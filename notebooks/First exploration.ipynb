{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "celtic-assist",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faced-fiction",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:43.564080Z",
     "start_time": "2022-01-03T19:29:43.558638Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.display import HTML\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from nltk.tokenize import sent_tokenize\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-click",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "promising-garbage",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:43.929376Z",
     "start_time": "2022-01-03T19:29:43.919794Z"
    }
   },
   "outputs": [],
   "source": [
    "CLASSES_COLORS = {\n",
    "    \"Lead\": \"Grey\",\n",
    "    \"Position\": \"YellowGreen\",\n",
    "    \"Claim\": \"#F1C40F\",\n",
    "    \"Counterclaim\": \"#E67E22\",\n",
    "    \"Rebuttal\": \"#873600\",\n",
    "    \"Evidence\": \"#3498DB\",\n",
    "    \"Concluding Statement\": \"Green\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-serbia",
   "metadata": {},
   "source": [
    "The following function print the essay text (keeping its exact original formatting) using colors to highlight discourse elements and their classes.\n",
    "\n",
    "It uses only `predictionstring`, which is useful to display models predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "phantom-oxide",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:44.178159Z",
     "start_time": "2022-01-03T19:29:44.167647Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None # Disabling some pandas warning\n",
    "\n",
    "def display_classes(essay_id, train_df):\n",
    "    elements_df = train_df[train_df[\"id\"] == essay_id]\n",
    "    essay_text = open(f'../raw_data/train/{essay_id}.txt').read()\n",
    "    essay_words = essay_text.split()\n",
    "    formatted_essay = \"\"\n",
    "    \n",
    "    # First we make sure discourse elements are in the text order\n",
    "    elements_df[\"prediction_list\"] = elements_df[\"predictionstring\"].map(lambda x : x.split())\n",
    "    elements_df[\"start_word_index\"] = elements_df[\"prediction_list\"].map(lambda x : int(x[0]))\n",
    "    elements_df.sort_values(\"start_word_index\", inplace=True)\n",
    "\n",
    "    # Then for each discourse element, we go word by word trough the original essay text\n",
    "    # and then we highlight the exact part of the essay corresponding to the discourse class.\n",
    "    end_char = 0\n",
    "    for i, element in elements_df.iterrows():\n",
    "        start_word = essay_words[element[\"start_word_index\"]] \n",
    "        start_char = essay_text[end_char:].find(start_word) + len(essay_text[:end_char])\n",
    "        formatted_essay += essay_text[end_char:start_char]\n",
    "        for word_index in element[\"prediction_list\"]:\n",
    "            word = essay_words[int(word_index)]\n",
    "            word_position = essay_text[end_char:].find(word)\n",
    "            if word_position == -1:\n",
    "                return \"Formatting failed\"\n",
    "            end_char = word_position + len(essay_text[:end_char]) + len(word)\n",
    "        formatted_essay += f\"|<span style='color:{CLASSES_COLORS[element['discourse_type']]}'>{essay_text[start_char:end_char]}</span>\"\n",
    "    formatted_essay = formatted_essay.replace(\"\\n\", \"<br>\")\n",
    "    color_labels = \" \".join([\n",
    "        f\"|<span style='color:{CLASSES_COLORS[class_]}'>{class_}</span>\"\n",
    "        for class_ in CLASSES_COLORS.keys()])\n",
    "    return HTML(color_labels + \"<br><br>\" + formatted_essay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-somerset",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-toolbox",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "addressed-myanmar",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:45.587626Z",
     "start_time": "2022-01-03T19:29:44.627716Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../raw_data/train.csv\", dtype = {\"discourse_id\": int, \"discourse_start\": int, \"discourse_end\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "convenient-animal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:45.623939Z",
     "start_time": "2022-01-03T19:29:45.590503Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627660524</td>\n",
       "      <td>8</td>\n",
       "      <td>229</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627653021</td>\n",
       "      <td>230</td>\n",
       "      <td>312</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627671020</td>\n",
       "      <td>313</td>\n",
       "      <td>401</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627696365</td>\n",
       "      <td>402</td>\n",
       "      <td>758</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627759780</td>\n",
       "      <td>759</td>\n",
       "      <td>886</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id   discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1622627660524                8            229   \n",
       "1  423A1CA112E2  1622627653021              230            312   \n",
       "2  423A1CA112E2  1622627671020              313            401   \n",
       "3  423A1CA112E2  1622627696365              402            758   \n",
       "4  423A1CA112E2  1622627759780              759            886   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-basin",
   "metadata": {},
   "source": [
    "## Class balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-prerequisite",
   "metadata": {},
   "source": [
    "We have an important class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "patient-tulsa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:45.663449Z",
     "start_time": "2022-01-03T19:29:45.629666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claim                   0.347959\n",
       "Evidence                0.316731\n",
       "Position                0.106859\n",
       "Concluding Statement    0.093594\n",
       "Lead                    0.064487\n",
       "Counterclaim            0.040314\n",
       "Rebuttal                0.030057\n",
       "Name: discourse_type, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"discourse_type\"].value_counts()/train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-shakespeare",
   "metadata": {},
   "source": [
    "## Are discourse elements full sentences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-morocco",
   "metadata": {},
   "source": [
    "Discourse elements that are sentences or groups of sentences (ie: starts with an uppercase letter and ends with a mark). The real number is higher because some students forget uppercase letters or final marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "national-storm",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:46.816874Z",
     "start_time": "2022-01-03T19:29:46.742324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5753778769586883"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_elements = [\n",
    "    (text[0].isupper() or text[1].isupper())\n",
    "    and (text[-1] in \".?!\" or text[-2] in \".?!\")\n",
    "    for text in train_df[\"discourse_text\"]\n",
    "]\n",
    "sentences_elements.count(True)/len(sentences_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-trader",
   "metadata": {},
   "source": [
    "Breakdown by discourse class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wound-tragedy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:47.203862Z",
     "start_time": "2022-01-03T19:29:47.023283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lead': 0.7219774314884471,\n",
       " 'Position': 0.510798365652766,\n",
       " 'Evidence': 0.7472539494989279,\n",
       " 'Claim': 0.43530911408540474,\n",
       " 'Concluding Statement': 0.5780821917808219,\n",
       " 'Counterclaim': 0.45212308750214886,\n",
       " 'Rebuttal': 0.45768964722158173}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_ratio = {}\n",
    "for class_ in train_df[\"discourse_type\"].unique():\n",
    "    class_df = train_df[\"discourse_text\"][train_df[\"discourse_type\"] == class_]\n",
    "    sentences_elements = [\n",
    "        (text[0].isupper() or text[1].isupper())\n",
    "        and (text[-1] in \".?!\" or text[-2] in \".?!\")\n",
    "        for text in class_df\n",
    "    ]\n",
    "    sentences_ratio.update({class_: sentences_elements.count(True)/len(sentences_elements)})\n",
    "sentences_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-accused",
   "metadata": {},
   "source": [
    "## Simplest baseline : tf-idf + statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-prince",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T09:12:47.655042Z",
     "start_time": "2021-12-29T09:12:47.572057Z"
    }
   },
   "source": [
    "Average count of discourse classes per essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stopped-depression",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:47.501919Z",
     "start_time": "2022-01-03T19:29:47.355502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discourse_type\n",
       "Claim                   3.363569\n",
       "Concluding Statement    1.006484\n",
       "Counterclaim            1.271198\n",
       "Evidence                2.939035\n",
       "Lead                    1.000430\n",
       "Position                1.003449\n",
       "Rebuttal                1.205392\n",
       "Name: discourse_id, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_ratio = train_df[[\"id\", \"discourse_id\", \"discourse_type\"]]\\\n",
    "    .groupby([\"id\", \"discourse_type\"]).count()\\\n",
    "    .groupby(\"discourse_type\").mean()\\\n",
    "    .squeeze()\n",
    "classes_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-hello",
   "metadata": {},
   "source": [
    "The strategy is to identify the following numbers of discourse classes when we \"predict\" a new essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "applicable-saint",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:47.624536Z",
     "start_time": "2022-01-03T19:29:47.608407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discourse_type\n",
       "Claim                   3\n",
       "Concluding Statement    1\n",
       "Counterclaim            1\n",
       "Evidence                3\n",
       "Lead                    1\n",
       "Position                1\n",
       "Rebuttal                1\n",
       "Name: discourse_id, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_ratio_rounded = classes_ratio.round().astype(int)\n",
    "classes_ratio_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "operational-bottle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:47.736173Z",
     "start_time": "2022-01-03T19:29:47.730476Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train_df[\"discourse_text\"]\n",
    "y = train_df[\"discourse_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "stretch-moisture",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:54.579815Z",
     "start_time": "2022-01-03T19:29:47.889329Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=False)\n",
    "X_vec = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-isaac",
   "metadata": {},
   "source": [
    "We use `ComplementNB` which is better suited than `MultinomialNB` for imbalanced classes (according to Sklearn doc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "threaded-found",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:55.487938Z",
     "start_time": "2022-01-03T19:29:54.583149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ComplementNB()\n",
    "model.fit(X_vec, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "encouraging-natural",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:55.874515Z",
     "start_time": "2022-01-03T19:29:55.492214Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6329620979534697"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_vec, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-lodging",
   "metadata": {},
   "source": [
    "Prediction :\n",
    "\n",
    "For each sentence, we compute the probability of belonging to each class, and store this into a Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "stylish-moldova",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:55.911105Z",
     "start_time": "2022-01-03T19:29:55.878247Z"
    }
   },
   "outputs": [],
   "source": [
    "essay_text = open(f'../raw_data/train/423A1CA112E2.txt').read()\n",
    "sentences = sent_tokenize(essay_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "noble-contributor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:55.958571Z",
     "start_time": "2022-01-03T19:29:55.926783Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_matrix = pd.DataFrame(model.predict_proba(vectorizer.transform(sentences)), columns=model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "documented-excitement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:56.021963Z",
     "start_time": "2022-01-03T19:29:55.971758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim</th>\n",
       "      <th>Concluding Statement</th>\n",
       "      <th>Counterclaim</th>\n",
       "      <th>Evidence</th>\n",
       "      <th>Lead</th>\n",
       "      <th>Position</th>\n",
       "      <th>Rebuttal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.131756</td>\n",
       "      <td>0.128818</td>\n",
       "      <td>0.134072</td>\n",
       "      <td>0.169805</td>\n",
       "      <td>0.165532</td>\n",
       "      <td>0.135662</td>\n",
       "      <td>0.134355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.121082</td>\n",
       "      <td>0.139310</td>\n",
       "      <td>0.130993</td>\n",
       "      <td>0.199631</td>\n",
       "      <td>0.154590</td>\n",
       "      <td>0.119632</td>\n",
       "      <td>0.134763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.139663</td>\n",
       "      <td>0.137054</td>\n",
       "      <td>0.135748</td>\n",
       "      <td>0.174339</td>\n",
       "      <td>0.138454</td>\n",
       "      <td>0.138590</td>\n",
       "      <td>0.136152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.149383</td>\n",
       "      <td>0.136265</td>\n",
       "      <td>0.136745</td>\n",
       "      <td>0.178759</td>\n",
       "      <td>0.133124</td>\n",
       "      <td>0.128224</td>\n",
       "      <td>0.137500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.126587</td>\n",
       "      <td>0.142706</td>\n",
       "      <td>0.173493</td>\n",
       "      <td>0.139626</td>\n",
       "      <td>0.153853</td>\n",
       "      <td>0.136008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.097770</td>\n",
       "      <td>0.118706</td>\n",
       "      <td>0.127384</td>\n",
       "      <td>0.273059</td>\n",
       "      <td>0.135602</td>\n",
       "      <td>0.117683</td>\n",
       "      <td>0.129797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.126523</td>\n",
       "      <td>0.116620</td>\n",
       "      <td>0.123425</td>\n",
       "      <td>0.283009</td>\n",
       "      <td>0.121389</td>\n",
       "      <td>0.106709</td>\n",
       "      <td>0.122325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.179811</td>\n",
       "      <td>0.141030</td>\n",
       "      <td>0.137283</td>\n",
       "      <td>0.131281</td>\n",
       "      <td>0.140885</td>\n",
       "      <td>0.134098</td>\n",
       "      <td>0.135611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.140098</td>\n",
       "      <td>0.156537</td>\n",
       "      <td>0.138972</td>\n",
       "      <td>0.114874</td>\n",
       "      <td>0.157105</td>\n",
       "      <td>0.154759</td>\n",
       "      <td>0.137655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.162999</td>\n",
       "      <td>0.137049</td>\n",
       "      <td>0.133890</td>\n",
       "      <td>0.150167</td>\n",
       "      <td>0.144898</td>\n",
       "      <td>0.136391</td>\n",
       "      <td>0.134606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.152943</td>\n",
       "      <td>0.142108</td>\n",
       "      <td>0.142665</td>\n",
       "      <td>0.133678</td>\n",
       "      <td>0.143072</td>\n",
       "      <td>0.147976</td>\n",
       "      <td>0.137558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.183616</td>\n",
       "      <td>0.133097</td>\n",
       "      <td>0.134721</td>\n",
       "      <td>0.144454</td>\n",
       "      <td>0.137702</td>\n",
       "      <td>0.129465</td>\n",
       "      <td>0.136945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.137355</td>\n",
       "      <td>0.142796</td>\n",
       "      <td>0.136644</td>\n",
       "      <td>0.153476</td>\n",
       "      <td>0.149714</td>\n",
       "      <td>0.142950</td>\n",
       "      <td>0.137064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.122281</td>\n",
       "      <td>0.167901</td>\n",
       "      <td>0.135521</td>\n",
       "      <td>0.159528</td>\n",
       "      <td>0.140040</td>\n",
       "      <td>0.136195</td>\n",
       "      <td>0.138535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.146534</td>\n",
       "      <td>0.139522</td>\n",
       "      <td>0.160264</td>\n",
       "      <td>0.125043</td>\n",
       "      <td>0.141569</td>\n",
       "      <td>0.145491</td>\n",
       "      <td>0.141579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.142384</td>\n",
       "      <td>0.146216</td>\n",
       "      <td>0.132700</td>\n",
       "      <td>0.191467</td>\n",
       "      <td>0.123676</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.140057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.122861</td>\n",
       "      <td>0.119771</td>\n",
       "      <td>0.124776</td>\n",
       "      <td>0.254295</td>\n",
       "      <td>0.134457</td>\n",
       "      <td>0.115093</td>\n",
       "      <td>0.128748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.124122</td>\n",
       "      <td>0.122299</td>\n",
       "      <td>0.132002</td>\n",
       "      <td>0.236225</td>\n",
       "      <td>0.131543</td>\n",
       "      <td>0.120981</td>\n",
       "      <td>0.132828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.148342</td>\n",
       "      <td>0.140135</td>\n",
       "      <td>0.131990</td>\n",
       "      <td>0.180266</td>\n",
       "      <td>0.134387</td>\n",
       "      <td>0.127591</td>\n",
       "      <td>0.137288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.119570</td>\n",
       "      <td>0.129775</td>\n",
       "      <td>0.123524</td>\n",
       "      <td>0.249046</td>\n",
       "      <td>0.133823</td>\n",
       "      <td>0.116919</td>\n",
       "      <td>0.127343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.121722</td>\n",
       "      <td>0.143932</td>\n",
       "      <td>0.129423</td>\n",
       "      <td>0.215149</td>\n",
       "      <td>0.130860</td>\n",
       "      <td>0.123847</td>\n",
       "      <td>0.135067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.146094</td>\n",
       "      <td>0.140641</td>\n",
       "      <td>0.136894</td>\n",
       "      <td>0.150828</td>\n",
       "      <td>0.143304</td>\n",
       "      <td>0.146203</td>\n",
       "      <td>0.136036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.162271</td>\n",
       "      <td>0.140201</td>\n",
       "      <td>0.133366</td>\n",
       "      <td>0.167496</td>\n",
       "      <td>0.134642</td>\n",
       "      <td>0.127071</td>\n",
       "      <td>0.134954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.140996</td>\n",
       "      <td>0.141865</td>\n",
       "      <td>0.137239</td>\n",
       "      <td>0.174495</td>\n",
       "      <td>0.137766</td>\n",
       "      <td>0.131773</td>\n",
       "      <td>0.135865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.131047</td>\n",
       "      <td>0.153688</td>\n",
       "      <td>0.131661</td>\n",
       "      <td>0.183561</td>\n",
       "      <td>0.134517</td>\n",
       "      <td>0.132529</td>\n",
       "      <td>0.132997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.134725</td>\n",
       "      <td>0.133195</td>\n",
       "      <td>0.135943</td>\n",
       "      <td>0.187154</td>\n",
       "      <td>0.145230</td>\n",
       "      <td>0.128370</td>\n",
       "      <td>0.135382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.163983</td>\n",
       "      <td>0.161190</td>\n",
       "      <td>0.135528</td>\n",
       "      <td>0.115308</td>\n",
       "      <td>0.137394</td>\n",
       "      <td>0.149090</td>\n",
       "      <td>0.137507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Claim  Concluding Statement  Counterclaim  Evidence      Lead  \\\n",
       "0   0.131756              0.128818      0.134072  0.169805  0.165532   \n",
       "1   0.121082              0.139310      0.130993  0.199631  0.154590   \n",
       "2   0.139663              0.137054      0.135748  0.174339  0.138454   \n",
       "3   0.149383              0.136265      0.136745  0.178759  0.133124   \n",
       "4   0.127726              0.126587      0.142706  0.173493  0.139626   \n",
       "5   0.097770              0.118706      0.127384  0.273059  0.135602   \n",
       "6   0.126523              0.116620      0.123425  0.283009  0.121389   \n",
       "7   0.179811              0.141030      0.137283  0.131281  0.140885   \n",
       "8   0.140098              0.156537      0.138972  0.114874  0.157105   \n",
       "9   0.162999              0.137049      0.133890  0.150167  0.144898   \n",
       "10  0.152943              0.142108      0.142665  0.133678  0.143072   \n",
       "11  0.183616              0.133097      0.134721  0.144454  0.137702   \n",
       "12  0.137355              0.142796      0.136644  0.153476  0.149714   \n",
       "13  0.122281              0.167901      0.135521  0.159528  0.140040   \n",
       "14  0.146534              0.139522      0.160264  0.125043  0.141569   \n",
       "15  0.142384              0.146216      0.132700  0.191467  0.123676   \n",
       "16  0.122861              0.119771      0.124776  0.254295  0.134457   \n",
       "17  0.124122              0.122299      0.132002  0.236225  0.131543   \n",
       "18  0.148342              0.140135      0.131990  0.180266  0.134387   \n",
       "19  0.119570              0.129775      0.123524  0.249046  0.133823   \n",
       "20  0.121722              0.143932      0.129423  0.215149  0.130860   \n",
       "21  0.146094              0.140641      0.136894  0.150828  0.143304   \n",
       "22  0.162271              0.140201      0.133366  0.167496  0.134642   \n",
       "23  0.140996              0.141865      0.137239  0.174495  0.137766   \n",
       "24  0.131047              0.153688      0.131661  0.183561  0.134517   \n",
       "25  0.134725              0.133195      0.135943  0.187154  0.145230   \n",
       "26  0.163983              0.161190      0.135528  0.115308  0.137394   \n",
       "\n",
       "    Position  Rebuttal  \n",
       "0   0.135662  0.134355  \n",
       "1   0.119632  0.134763  \n",
       "2   0.138590  0.136152  \n",
       "3   0.128224  0.137500  \n",
       "4   0.153853  0.136008  \n",
       "5   0.117683  0.129797  \n",
       "6   0.106709  0.122325  \n",
       "7   0.134098  0.135611  \n",
       "8   0.154759  0.137655  \n",
       "9   0.136391  0.134606  \n",
       "10  0.147976  0.137558  \n",
       "11  0.129465  0.136945  \n",
       "12  0.142950  0.137064  \n",
       "13  0.136195  0.138535  \n",
       "14  0.145491  0.141579  \n",
       "15  0.123500  0.140057  \n",
       "16  0.115093  0.128748  \n",
       "17  0.120981  0.132828  \n",
       "18  0.127591  0.137288  \n",
       "19  0.116919  0.127343  \n",
       "20  0.123847  0.135067  \n",
       "21  0.146203  0.136036  \n",
       "22  0.127071  0.134954  \n",
       "23  0.131773  0.135865  \n",
       "24  0.132529  0.132997  \n",
       "25  0.128370  0.135382  \n",
       "26  0.149090  0.137507  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-literacy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T10:38:17.012241Z",
     "start_time": "2022-01-03T10:38:17.005354Z"
    }
   },
   "source": [
    "Now, we want to assign a certain number of sentences to each class depending on `classes_ratio_rounded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "convinced-silence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:56.077369Z",
     "start_time": "2022-01-03T19:29:56.027493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 'Evidence'),\n",
       " (5, 'Evidence'),\n",
       " (16, 'Evidence'),\n",
       " (11, 'Claim'),\n",
       " (7, 'Claim'),\n",
       " (13, 'Concluding Statement'),\n",
       " (0, 'Lead'),\n",
       " (26, 'Claim'),\n",
       " (14, 'Counterclaim'),\n",
       " (8, 'Position'),\n",
       " (15, 'Rebuttal')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = []\n",
    "classes_count = classes_ratio_rounded.copy()\n",
    "sentences_nb = min(classes_count.sum(), len(sentences))\n",
    "while len(prediction) < sentences_nb :\n",
    "    highest_score_class = predictions_matrix.max().idxmax()\n",
    "    highest_score_element = predictions_matrix[highest_score_class].idxmax()\n",
    "    prediction.append((highest_score_element, highest_score_class))\n",
    "    predictions_matrix.drop(highest_score_element, inplace=True)\n",
    "    classes_count[highest_score_class] -= 1\n",
    "    if classes_count[highest_score_class] == 0:\n",
    "        predictions_matrix.drop(columns=highest_score_class, inplace=True)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-treasury",
   "metadata": {},
   "source": [
    "# Unused utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-heavy",
   "metadata": {},
   "source": [
    "`display_classes_2` uses the `discourse_text` field of `train_df`. It is generally better than `display_classes_3` (which uses `discourse_start/end`), but when a element is present several times in the essay text, things get messy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bottom-marble",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:56.119225Z",
     "start_time": "2022-01-03T19:29:56.088265Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_classes_2(essay_id, train_df):\n",
    "    elements_df = train_df[train_df[\"id\"] == essay_id]\n",
    "    essay_text = open(f'../raw_data/train/{essay_id}.txt').read()\n",
    "    for i, element in elements_df.iterrows():\n",
    "        element_text = element[\"discourse_text\"].strip()\n",
    "        # The stripping above is needed to make sure the replace below works\n",
    "        if not element_text in essay_text:\n",
    "            return \"Formatting failed\"\n",
    "        essay_text = essay_text.replace(\n",
    "            element_text,\n",
    "            f\"|<span style='color:{CLASSES_COLORS[element['discourse_type']]}'>{element_text}</span>\"\n",
    "        )\n",
    "    essay_text = essay_text.replace(\"\\n\", \"<br>\")\n",
    "    color_labels = \" - \".join([\n",
    "        f\"<span style='color:{CLASSES_COLORS[class_]}'>{class_}</span>\"\n",
    "        for class_ in CLASSES_COLORS.keys()])\n",
    "    return HTML(color_labels + \"<br><br>\" + essay_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "handled-average",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:56.145577Z",
     "start_time": "2022-01-03T19:29:56.139493Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_discourse(text, type_):\n",
    "    if text:\n",
    "        text = text.replace(\"\\n\", \"<br>\")\n",
    "        return f\"|<span style='color:{CLASSES_COLORS.get(type_)}'>{text}</span>\"\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "active-parking",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-03T19:29:56.174629Z",
     "start_time": "2022-01-03T19:29:56.158839Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_classes_3(essay_id, train_df):\n",
    "    elements_df = train_df[train_df[\"id\"] == essay_id]\n",
    "    essay_text = open(f'../raw_data/train/{essay_id}.txt').read()\n",
    "    formatted_elements = \"\"\n",
    "    char_pointer = 0\n",
    "    for i, element in elements_df.iterrows():\n",
    "        unlabelled_element = essay_text[char_pointer:element['discourse_start']]\n",
    "        char_pointer = element['discourse_end'] + 1\n",
    "        discourse_element = essay_text[element['discourse_start']:char_pointer]\n",
    "        formatted_elements +=\\\n",
    "            format_discourse(unlabelled_element, \"Unlabelled\") +\\\n",
    "            format_discourse(discourse_element, element['discourse_type'])\n",
    "    formatted_elements += essay_text[char_pointer:]\n",
    "    color_labels = \" \".join([format_discourse(class_, class_) for class_ in CLASSES_COLORS.keys()])\n",
    "    return HTML(color_labels + \"<br><br>\" + formatted_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-array",
   "metadata": {},
   "source": [
    "We maybe can simplify the code using the displaCy tool (https://explosion.ai/demos/displacy-ent), see this example:\n",
    "```python\n",
    "j = 40\n",
    "ents = []\n",
    "for i, row in df[df['id'] == df_f[j][35:-4]].iterrows():\n",
    "    ents.append({\n",
    "                    'start': int(row['discourse_start']), \n",
    "                     'end': int(row['discourse_end']), \n",
    "                     'label': row['discourse_type']\n",
    "                })\n",
    "with open(df_f[j], 'r') as file: data = file.read()\n",
    "\n",
    "doc2 = {\n",
    "    \"text\": data,\n",
    "    \"ents\": ents,\n",
    "}\n",
    "cols = {'Lead': '#dad1f6','Position': '#f9d5de','Claim': '#adcfad','Evidence': '#fbbf9a','Counterclaim': '#bdf2fa','Concluding Statement': '#eea69e','Rebuttal': '#d1f8f4'}\n",
    "options = {\"ents\": df.discourse_type.unique().tolist(), \"colors\": cols}\n",
    "displacy.render(doc2, style=\"ent\", options=options, manual=True, jupyter=True);\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
