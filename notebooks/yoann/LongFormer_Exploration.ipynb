{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11aa8ada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:50:04.344196Z",
     "start_time": "2022-01-07T16:49:58.940341Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 17:50:01.839990: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-07 17:50:01.840065: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8206e34a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:50:04.516403Z",
     "start_time": "2022-01-07T16:50:04.347411Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c95605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:50:05.483602Z",
     "start_time": "2022-01-07T16:50:04.519967Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf80b682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:50:05.499758Z",
     "start_time": "2022-01-07T16:50:05.487176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144293, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a324227a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:50:05.574949Z",
     "start_time": "2022-01-07T16:50:05.502676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aca0596",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:50:07.486493Z",
     "start_time": "2022-01-07T16:50:07.483184Z"
    }
   },
   "outputs": [],
   "source": [
    "# X = train.drop(columns = \"predictionstring\")\n",
    "# y = train.predictionstring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa3e9e6",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10023bd",
   "metadata": {},
   "source": [
    "### Importing and saving locally (not necesary, only for offline use) the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bd3e74",
   "metadata": {},
   "source": [
    "We are using the AutoTokenizer class from HuggingFace transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f5b2b13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:51:33.511808Z",
     "start_time": "2022-01-07T16:51:33.508587Z"
    }
   },
   "outputs": [],
   "source": [
    "#Change with path of saved tokens if they have already been generated (optionnal)\n",
    "\n",
    "LOAD_TOKENS_FROM = None\n",
    "\n",
    "\n",
    "# Once the tokens have been generated, you can uncomment this line:\n",
    "LOAD_TOKENS_FROM = \"../tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a1543c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:50:23.857295Z",
     "start_time": "2022-01-07T16:50:17.319138Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "433d6de1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:39:39.364507Z",
     "start_time": "2022-01-07T16:39:39.355383Z"
    }
   },
   "outputs": [],
   "source": [
    "#Saving the model locally\n",
    "if os.path.exists(\"../model\") == False: \n",
    "    os.mkdir(\"../model\")\n",
    "tokenizer.save_pretrained('../model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a446592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:50:27.533835Z",
     "start_time": "2022-01-07T16:50:26.358831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongformerConfig {\n",
       "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
       "  \"attention_mode\": \"longformer\",\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"attention_window\": [\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512\n",
       "  ],\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"ignore_attention_mask\": false,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 4098,\n",
       "  \"model_type\": \"longformer\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"sep_token_id\": 2,\n",
       "  \"transformers_version\": \"4.15.0\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the vanilla configuration for the model:\n",
    "config = transformers.AutoConfig.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26506e60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T14:08:17.252013Z",
     "start_time": "2022-01-07T14:08:17.246910Z"
    }
   },
   "outputs": [],
   "source": [
    "config.save_pretrained(\"../model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2917fc23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:50:52.139427Z",
     "start_time": "2022-01-07T16:50:30.544237Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 17:50:33.173433: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-07 17:50:33.196057: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: UNKNOWN ERROR (100)\n",
      "2022-01-07 17:50:33.196094: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-I5V260QJ): /proc/driver/nvidia/version does not exist\n",
      "2022-01-07 17:50:33.196544: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some layers from the model checkpoint at allenai/longformer-base-4096 were not used when initializing TFLongformerModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFLongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFLongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFLongformerModel were initialized from the model checkpoint at allenai/longformer-base-4096.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFLongformerModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.models.longformer.modeling_tf_longformer.TFLongformerModel at 0x7f06b5c632b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone = transformers.TFAutoModel.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00ada81d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T14:13:52.949278Z",
     "start_time": "2022-01-07T14:13:48.366389Z"
    }
   },
   "outputs": [],
   "source": [
    "backbone.save_pretrained(\"../model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f3f08a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:50:52.152276Z",
     "start_time": "2022-01-07T16:50:52.143611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking Tensorflow version:\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca86b35a",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a174d0d",
   "metadata": {},
   "source": [
    "### If the tokens have already been generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81ce546f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:51:43.300626Z",
     "start_time": "2022-01-07T16:51:38.369469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded NER tokens\n"
     ]
    }
   ],
   "source": [
    "#Max lenght of tokens\n",
    "MAX_LEN = 1024\n",
    "\n",
    "targets = np.load(f'{LOAD_TOKENS_FROM}/targets_{MAX_LEN}.npy')\n",
    "train_tokens = np.load(f'{LOAD_TOKENS_FROM}/tokens_{MAX_LEN}.npy')\n",
    "train_attention = np.load(f'{LOAD_TOKENS_FROM}/attention_{MAX_LEN}.npy')\n",
    "print('Loaded NER tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dd5dfd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:51:45.870648Z",
     "start_time": "2022-01-07T16:51:45.852014Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ee519c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:50:58.814226Z",
     "start_time": "2022-01-07T16:50:58.797488Z"
    }
   },
   "outputs": [],
   "source": [
    "#number of unique id of texts: \n",
    "\n",
    "IDS = len(train.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da9b6059",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T15:22:05.002345Z",
     "start_time": "2022-01-07T15:22:04.997140Z"
    }
   },
   "outputs": [],
   "source": [
    "train_tokens = np.zeros((IDS,MAX_LEN), dtype='int32')\n",
    "\n",
    "#Generating an attention mask:\n",
    "\n",
    "train_attention = np.zeros((IDS,MAX_LEN), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7a3c826",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T15:54:20.514208Z",
     "start_time": "2022-01-07T15:54:20.505206Z"
    }
   },
   "outputs": [],
   "source": [
    "#Generating tensor that will be filled with the coordinates of the start and end of the named entities.\n",
    "\n",
    "lead_b = np.zeros((IDS,MAX_LEN))\n",
    "lead_i = np.zeros((IDS,MAX_LEN))\n",
    "\n",
    "position_b = np.zeros((IDS,MAX_LEN))\n",
    "position_i = np.zeros((IDS,MAX_LEN))\n",
    "\n",
    "evidence_b = np.zeros((IDS,MAX_LEN))\n",
    "evidence_i = np.zeros((IDS,MAX_LEN))\n",
    "\n",
    "claim_b = np.zeros((IDS,MAX_LEN))\n",
    "claim_i = np.zeros((IDS,MAX_LEN))\n",
    "\n",
    "conclusion_b = np.zeros((IDS,MAX_LEN))\n",
    "conclusion_i = np.zeros((IDS,MAX_LEN))\n",
    "\n",
    "counterclaim_b = np.zeros((IDS,MAX_LEN))\n",
    "counterclaim_i = np.zeros((IDS,MAX_LEN))\n",
    "\n",
    "rebuttal_b = np.zeros((IDS,MAX_LEN))\n",
    "rebuttal_i = np.zeros((IDS,MAX_LEN))\n",
    "\n",
    "# HELPER VARIABLES\n",
    "\n",
    "#List of number of words in each text:\n",
    "train_lens = []\n",
    "\n",
    "targets_b = [lead_b, position_b, evidence_b, claim_b, conclusion_b, counterclaim_b, rebuttal_b]\n",
    "targets_i = [lead_i, position_i, evidence_i, claim_i, conclusion_i, counterclaim_i, rebuttal_i]\n",
    "target_map = {'Lead':0, 'Position':1, 'Evidence':2, 'Claim':3, 'Concluding Statement':4,\n",
    "             'Counterclaim':5, 'Rebuttal':6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6a9f966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T15:54:20.781115Z",
     "start_time": "2022-01-07T15:54:20.766606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A8445CABFECE'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.id.unique()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5885f60e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:12:41.614566Z",
     "start_time": "2022-01-07T16:05:21.916942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , 4600 , 4700 , 4800 , 4900 , 5000 , 5100 , 5200 , 5300 , 5400 , 5500 , 5600 , 5700 , 5800 , 5900 , 6000 , 6100 , 6200 , 6300 , 6400 , 6500 , 6600 , 6700 , 6800 , 6900 , 7000 , 7100 , 7200 , 7300 , 7400 , 7500 , 7600 , 7700 , 7800 , 7900 , 8000 , 8100 , 8200 , 8300 , 8400 , 8500 , 8600 , 8700 , 8800 , 8900 , 9000 , 9100 , 9200 , 9300 , 9400 , 9500 , 9600 , 9700 , 9800 , 9900 , 10000 , 10100 , 10200 , 10300 , 10400 , 10500 , 10600 , 10700 , 10800 , 10900 , 11000 , 11100 , 11200 , 11300 , 11400 , 11500 , 11600 , 11700 , 11800 , 11900 , 12000 , 12100 , 12200 , 12300 , 12400 , 12500 , 12600 , 12700 , 12800 , 12900 , 13000 , 13100 , 13200 , 13300 , 13400 , 13500 , 13600 , 13700 , 13800 , 13900 , 14000 , 14100 , 14200 , 14300 , 14400 , 14500 , 14600 , 14700 , 14800 , 14900 , 15000 , 15100 , 15200 , 15300 , 15400 , 15500 , "
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "for unique_text in range(IDS):\n",
    "#     pdb.set_trace()\n",
    "    #little print between each 100 iterations:\n",
    "    if unique_text%100==0: print(unique_text,', ',end='')\n",
    "    \n",
    "    text = train.id.unique()[unique_text]\n",
    "    name = f'../data/train/{text}.txt'\n",
    "    opened_text = open(name, 'r').read()\n",
    "    train_lens.append( len(opened_text.split()))\n",
    "    tokens = tokenizer.encode_plus(opened_text, \n",
    "                                   #max lenght of tokens\n",
    "                                   max_length=MAX_LEN, \n",
    "                                   \n",
    "                                   #padding = puttinh each token at the same lenght\n",
    "                                   padding='max_length',\n",
    "                                   \n",
    "                                   #either or not we truncate the string to a certain lenght\n",
    "                                   truncation=True, \n",
    "                                   \n",
    "                                   #starting char and ending char for each token\n",
    "                                   return_offsets_mapping=True)\n",
    "    \n",
    "    #Placing the value of the token start and end ids in the  train_tokens tensor:\n",
    "    train_tokens[unique_text,] = tokens['input_ids']\n",
    "    \n",
    "    #Placing the value of the token attention_mask ids in the  train_attention tensor:\n",
    "    train_attention[unique_text,] = tokens['attention_mask']\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    ######################### Find the target in the text on save it in a target array ##############################\n",
    "    offsets = tokens['offset_mapping']\n",
    "    offset_index = 0\n",
    "    df = train.loc[train.id==text]\n",
    "    \n",
    "    \n",
    "    #Iterating through each text:\n",
    "    for index,row in df.iterrows():\n",
    "        start = row.discourse_start\n",
    "        end = row.discourse_end\n",
    "        if offset_index>len(offsets)-1:\n",
    "            break\n",
    "        c_ = offsets[offset_index][0]\n",
    "        d_= offsets[offset_index][1]\n",
    "        beginning = True\n",
    "        while end>c_:\n",
    "            \n",
    "            if (c_>=start)&(end>=d_):\n",
    "                k = target_map[row.discourse_type]\n",
    "                #Assigning the correct target label for each token offset\n",
    "                if beginning:\n",
    "                    targets_b[k][unique_text][offset_index] = 1\n",
    "                    beginning = False\n",
    "                else:\n",
    "                    targets_i[k][unique_text][offset_index] = 1\n",
    "            offset_index += 1\n",
    "            if offset_index>len(offsets)-1:\n",
    "                break\n",
    "            c_ = offsets[offset_index][0]\n",
    "            d_ = offsets[offset_index][1]\n",
    "            \n",
    "    ################################################ target array generated #########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f54d59a",
   "metadata": {},
   "source": [
    "### WIP Comparison between words count and token counter, to define an optimal MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "170cafe1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:12:42.153170Z",
     "start_time": "2022-01-07T16:12:41.618315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_lens,bins=100)\n",
    "plt.title('Histogram of Train Word Counts',size=16)\n",
    "plt.xlabel('Train Word Count',size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4048400a",
   "metadata": {},
   "source": [
    "### Generating a target array (and optionnaly saving it locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "744bf5c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:35:45.338115Z",
     "start_time": "2022-01-07T16:35:39.771241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved NER tokens\n"
     ]
    }
   ],
   "source": [
    "#Generating a target array\n",
    "\n",
    "\n",
    "## //!\\\\: Still not clear to me the last dimension of the array: why 15? Do we need a 15th with only 0 in it ?\n",
    "# Update : for the tokens that have not been linked to a label?\n",
    "\n",
    "\n",
    "if LOAD_TOKENS_FROM is None:\n",
    "#     pdb.set_trace()\n",
    "    targets = np.zeros((IDS,MAX_LEN,15), dtype='int32')\n",
    "    for k in range(7):\n",
    "        targets[:,:,2*k] = targets_b[k]\n",
    "        targets[:,:,2*k+1] = targets_i[k]\n",
    "    targets[:,:,14] = 1-np.max(targets,axis=-1)\n",
    "    \n",
    "    \n",
    "if LOAD_TOKENS_FROM is None:\n",
    "    if os.path.exists(\"../tokens\") == False: \n",
    "        os.mkdir(\"../tokens\")\n",
    "    np.save(f'../tokens/targets_{MAX_LEN}', targets)\n",
    "    np.save(f'../tokens/tokens_{MAX_LEN}', train_tokens)\n",
    "    np.save(f'../tokens/attention_{MAX_LEN}', train_attention)\n",
    "    print('Saved NER tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b846a8be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:31:47.092957Z",
     "start_time": "2022-01-07T16:31:47.086996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15594, 1024)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_b[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c95c095",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30539ee",
   "metadata": {},
   "source": [
    "We use the backbone we already loaded as the base of our model, and we had the last layers corresponding to our task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "242d8e18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T16:51:58.716569Z",
     "start_time": "2022-01-07T16:51:58.677543Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    tokens = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'tokens', dtype=tf.int32)\n",
    "    attention = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'attention', dtype=tf.int32)\n",
    "    \n",
    "    config = transformers.AutoConfig.from_pretrained('../model/config.json') \n",
    "    backbone = transformers.TFAutoModel.from_pretrained('../model/tf_model.h5', config=config)\n",
    "    \n",
    "    x = backbone(tokens, attention_mask=attention)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x[0])\n",
    "    x = tf.keras.layers.Dense(15, activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[tokens,attention], outputs=x)\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr = 1e-4),\n",
    "                  loss = [tf.keras.losses.CategoricalCrossentropy()],\n",
    "                  metrics = [tf.keras.metrics.CategoricalAccuracy()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37cdaa9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-07T16:52:01.263Z"
    }
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc5489f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
