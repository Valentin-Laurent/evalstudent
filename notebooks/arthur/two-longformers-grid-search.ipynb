{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports and helpers","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import gc\ngc.enable()\nimport sys\nimport os\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom joblib import Parallel, delayed\nfrom transformers import AutoConfig, AutoModel, AutoTokenizer\nfrom tqdm.notebook import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-15T13:13:23.175744Z","iopub.execute_input":"2022-03-15T13:13:23.176691Z","iopub.status.idle":"2022-03-15T13:13:24.830338Z","shell.execute_reply.started":"2022-03-15T13:13:23.176566Z","shell.execute_reply":"2022-03-15T13:13:24.829576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helpers/functions from the original \"2 longformers\" Notebook","metadata":{}},{"cell_type":"code","source":"target_id_map = {\n    \"B-Lead\": 0,\n    \"I-Lead\": 1,\n    \"B-Position\": 2,\n    \"I-Position\": 3,\n    \"B-Evidence\": 4,\n    \"I-Evidence\": 5,\n    \"B-Claim\": 6,\n    \"I-Claim\": 7,\n    \"B-Concluding Statement\": 8,\n    \"I-Concluding Statement\": 9,\n    \"B-Counterclaim\": 10,\n    \"I-Counterclaim\": 11,\n    \"B-Rebuttal\": 12,\n    \"I-Rebuttal\": 13,\n    \"O\": 14,\n    \"PAD\": -100,\n}\n\n\nid_target_map = {v: k for k, v in target_id_map.items()}\n\nclass args1:\n    input_path = \"../input/feedback-prize-2021/\"\n    model = \"../input/longformerlarge4096/longformer-large-4096/\"\n    tez_model= \"../input/fblongformerlarge1536/\"\n    output = \".\"\n    batch_size = 8\n    max_len = 4096\n    \nclass args2:\n    input_path = \"../input/feedback-prize-2021/\"\n    model = \"../input/longformerlarge4096/longformer-large-4096/\"\n    tez_model= \"../input/tez-fb-large/\"\n    output = \".\"\n    batch_size = 8\n    max_len = 4096","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:14:12.209846Z","iopub.execute_input":"2022-03-15T13:14:12.210137Z","iopub.status.idle":"2022-03-15T13:14:12.218356Z","shell.execute_reply.started":"2022-03-15T13:14:12.210105Z","shell.execute_reply":"2022-03-15T13:14:12.217462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _prepare_test_data_helper(args, tokenizer, ids, train_or_test):\n    test_samples = []\n    for idx in ids:\n        filename = os.path.join(args.input_path, train_or_test, idx + \".txt\")\n        with open(filename, \"r\") as f:\n            text = f.read()\n\n        encoded_text = tokenizer.encode_plus(\n            text,\n            add_special_tokens=False,\n            return_offsets_mapping=True,\n        )\n        input_ids = encoded_text[\"input_ids\"]\n        offset_mapping = encoded_text[\"offset_mapping\"]\n\n        sample = {\n            \"id\": idx,\n            \"input_ids\": input_ids,\n            \"text\": text,\n            \"offset_mapping\": offset_mapping,\n        }\n\n        test_samples.append(sample)\n    return test_samples\n\n\ndef prepare_test_data(ids, tokenizer, args, train_or_test):\n    test_samples = []\n    ids_splits = np.array_split(ids, 4)\n\n    results = Parallel(n_jobs=4, backend=\"multiprocessing\")(\n        delayed(_prepare_test_data_helper)(args, tokenizer, idx, train_or_test) for idx in ids_splits\n    )\n    for result in results:\n        test_samples.extend(result)\n\n    return test_samples","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:14:12.493714Z","iopub.execute_input":"2022-03-15T13:14:12.493981Z","iopub.status.idle":"2022-03-15T13:14:12.503657Z","shell.execute_reply.started":"2022-03-15T13:14:12.493952Z","shell.execute_reply":"2022-03-15T13:14:12.502674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metric calculation functions","metadata":{}},{"cell_type":"code","source":"CLASSES_LIST = [\n    \"Lead\",\n    \"Position\",\n    \"Claim\",\n    \"Counterclaim\",\n    \"Rebuttal\",\n    \"Evidence\",\n    \"Concluding Statement\"\n]","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:14:13.304774Z","iopub.execute_input":"2022-03-15T13:14:13.305058Z","iopub.status.idle":"2022-03-15T13:14:13.309526Z","shell.execute_reply.started":"2022-03-15T13:14:13.305026Z","shell.execute_reply":"2022-03-15T13:14:13.308632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Code adapted from Rob Mulla (@robikscube) (https://www.kaggle.com/robikscube/student-writing-competition-twitch)\ndef is_match(row):\n    \"\"\"\n    Returns  if prediction and ground truth are matching.\n    Only used internally in get_scores.\n    \"\"\"\n    set_pred = set(row.predictionstring_pred.split(\" \"))\n    set_gt = set(row.predictionstring_gt.split(\" \"))\n    inter = len(set_gt.intersection(set_pred))\n    overlap_1 = inter / len(set_gt)\n    overlap_2 = inter / len(set_pred)\n    return overlap_1 >= 0.5 and overlap_2 >= 0.5","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:14:13.691618Z","iopub.execute_input":"2022-03-15T13:14:13.691888Z","iopub.status.idle":"2022-03-15T13:14:13.69807Z","shell.execute_reply.started":"2022-03-15T13:14:13.69186Z","shell.execute_reply":"2022-03-15T13:14:13.697028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_scores(pred_df, gt_df):\n    \"\"\"\n    Returns precision, recall and f1 scores. Only used internally in kaggle_score\n    for one class at a time.\n    \"\"\"\n\n    # Checking DataFrames emptiness before proceeding with calculations:\n    nan_metrics_nb = 0\n    \n    if pred_df.empty:\n        precision = np.nan # Precision has no mathematical meaning in that case\n        recall = 0\n        nan_metrics_nb += 1\n    \n    if gt_df.empty:\n        precision = 0\n        recall = np.nan # Recall has no mathematical meaning in that case\n        nan_metrics_nb += 1\n    \n    if nan_metrics_nb > 0:\n        return {\n            \"precision\" : precision,\n            \"recall\" : recall,\n            \"f1\" : np.nan if nan_metrics_nb == 2 else 0\n        }\n    \n    # If no DataFrame is empty, we proceed:\n    gt_df = gt_df[[\"id\", \"discourse_type\", \"predictionstring\"]].reset_index(drop=True).copy()\n    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]].reset_index(drop=True).copy()\n    pred_df[\"pred_id\"] = pred_df.index\n    gt_df[\"gt_id\"] = gt_df.index\n\n    # All ground truths and predictions for a given class are compared.\n    joined = pred_df.merge(\n        gt_df,\n        left_on=[\"id\", \"class\"],\n        right_on=[\"id\", \"discourse_type\"],\n        how=\"outer\",\n        suffixes=(\"_pred\", \"_gt\"),\n    ).fillna(\"\")\n\n    # Purposedly ignoring multiple match possibilty (very unlikely) for efficiency\n    tp_df = joined[joined.apply(is_match, axis=1)]\n\n    TP = tp_df.shape[0]\n    FP = pred_df.drop(tp_df[\"pred_id\"]).shape[0]\n    FN = gt_df.drop(tp_df[\"gt_id\"]).shape[0]\n    \n    # Returning metrics\n    return {\n        \"precision\" : TP / (TP + FP),\n        \"recall\" : TP / (TP + FN),\n        \"f1\" : TP / (TP + 0.5 * (FP + FN))\n    }","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:14:14.371253Z","iopub.execute_input":"2022-03-15T13:14:14.371713Z","iopub.status.idle":"2022-03-15T13:14:14.383591Z","shell.execute_reply.started":"2022-03-15T13:14:14.371666Z","shell.execute_reply":"2022-03-15T13:14:14.382863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def kaggle_score(pred_df, gt_df, return_details=False):\n    \"\"\"\n    A function that scores for the kaggle Student Writing Competition\n\n    Uses the steps in the evaluation page, with a simplified (= random)\n    calculation when 2 matches exist for the same discourse element. \n    See https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n    \"\"\"\n    scores = [\n        get_scores(\n            pred_df[pred_df[\"class\"] == class_],\n            gt_df[gt_df[\"discourse_type\"] == class_]\n        )\n        for class_ in CLASSES_LIST   \n    ]\n    f1_score = np.nanmean([class_scores[\"f1\"] for class_scores in scores])\n    if return_details:\n        return f1_score, dict(zip(CLASSES_LIST, scores))\n    return f1_score","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:14:15.008342Z","iopub.execute_input":"2022-03-15T13:14:15.008819Z","iopub.status.idle":"2022-03-15T13:14:15.015907Z","shell.execute_reply.started":"2022-03-15T13:14:15.008771Z","shell.execute_reply":"2022-03-15T13:14:15.015336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generating predictions","metadata":{}},{"cell_type":"code","source":"def jn(pst, start, end):\n    return \" \".join([str(x) for x in pst[start:end]])\n\n\ndef link_evidence(oof):\n    thresh = 1\n    thresh2 = 26\n    idu = oof['id'].unique()\n    eoof = oof[oof['class'] == \"Evidence\"]\n    neoof = oof[oof['class'] != \"Evidence\"]\n    retval = []\n    for idv in idu:\n        q = eoof[(eoof['id'] == idv)]\n        if len(q) == 0:\n            continue\n        pst = []\n        c=\"Evidence\"\n        for i,r in q.iterrows():\n            pst = pst +[-1] + [int(x) for x in r['predictionstring'].split()]\n        start = 1\n        end = 1\n        for i in range(2,len(pst)):\n            cur = pst[i]\n            end = i\n            #if pst[start] == 205:\n            #   print(cur, pst[start], cur - pst[start])\n            if (cur == -1 and c != 'Evidence') or ((cur == -1) and ((pst[i+1] > pst[end-1] + thresh) or (pst[i+1] - pst[start] > thresh2))):\n                retval.append((idv, c, jn(pst, start, end)))\n                start = i + 1\n        v = (idv, c, jn(pst, start, end+1))\n        #print(v)\n        retval.append(v)\n    roof = pd.DataFrame(retval, columns = ['id', 'class', 'predictionstring']) \n    roof = roof.merge(neoof, how='outer')\n    return roof","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:49:59.376981Z","iopub.execute_input":"2022-03-15T13:49:59.377261Z","iopub.status.idle":"2022-03-15T13:49:59.38956Z","shell.execute_reply.started":"2022-03-15T13:49:59.377232Z","shell.execute_reply":"2022-03-15T13:49:59.388919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating a weighted average of the 2 models\n\ndef weighting_pred(dict_preds,alpha=.5):\n\n    for fold in range(5):\n        dict_preds[f\"fold{fold}\"][\"model_avg\"] = []\n        preds_model0 = dict_preds[f\"fold{fold}\"][\"model0\"]\n        preds_model1 = dict_preds[f\"fold{fold}\"][\"model1\"]\n        for batch_preds0, batch_preds1 in zip(preds_model0,preds_model1):\n            batch_preds_avg = batch_preds0*alpha0 + batch_preds1*(1-alpha0)\n            dict_preds[f\"fold{fold}\"][\"model_avg\"].append(batch_preds_avg)\n        #del dict_preds[f\"fold{fold}\"][\"model0\"]\n        #del dict_preds[f\"fold{fold}\"][\"model1\"]\n        \n    return dict_preds","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:15:31.733438Z","iopub.execute_input":"2022-03-15T13:15:31.733728Z","iopub.status.idle":"2022-03-15T13:15:31.739534Z","shell.execute_reply.started":"2022-03-15T13:15:31.733698Z","shell.execute_reply":"2022-03-15T13:15:31.738596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### CREATE FOLDS \n\ntrain_df = pd.read_csv(\"../input/feedback-prize-2021/train.csv\")\n\ndef creating_predictions_per_fold(dict_preds):\n    \"\"\" Returns a list of the test_samples var for the 5 folds, directly from dict with all preds\"\"\"\n    \n    folds = {}\n    folds_ids = {}\n    \n    for fold_number in range(5):\n        \n        ids_fold = pd.read_csv(\"../input/ids-fold/ids_folds.csv\")\n        ids_fold_i = ids_fold.id[ids_fold.kfold == fold_number].values\n\n        # We need the preprocessing stuff\n        # In order to make the code of the cells below work\n        tokenizer = AutoTokenizer.from_pretrained(args1.model)\n        train_or_test = \"train\"\n        test_samples = prepare_test_data(ids_fold_i, tokenizer, args1, \"train\")\n\n        # Creating raw_preds for the fold\n        raw_preds = dict_preds[f\"fold{fold_number}\"][\"model_avg\"]\n\n        final_preds = []\n        final_scores = []\n\n        for rp in raw_preds:\n            pred_class = np.argmax(rp, axis=2)\n            pred_scrs = np.max(rp, axis=2)\n            for pred, pred_scr in zip(pred_class, pred_scrs):\n                pred = pred.tolist()\n                pred_scr = pred_scr.tolist()\n                final_preds.append(pred)\n                final_scores.append(pred_scr)\n\n        for j in range(len(test_samples)):\n            tt = [id_target_map[p] for p in final_preds[j][1:]]\n            tt_score = final_scores[j][1:]\n            test_samples[j][\"preds\"] = tt\n            test_samples[j][\"pred_scores\"] = tt_score\n        \n        folds[fold_number] = test_samples\n        folds_ids[fold_number] = ids_fold_i\n    \n    return folds,folds_ids","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:33:16.199989Z","iopub.execute_input":"2022-03-15T13:33:16.2005Z","iopub.status.idle":"2022-03-15T13:33:17.215826Z","shell.execute_reply.started":"2022-03-15T13:33:16.20045Z","shell.execute_reply":"2022-03-15T13:33:17.215184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_submission_df_per_fold(test_samples,proba_thresh,min_thresh):\n    \"\"\"Returns the submission df from a given fold (test_samples) with params thresh\"\"\"\n    \n    submission = []\n    for sample_idx, sample in enumerate(test_samples):\n        preds = sample[\"preds\"]\n        offset_mapping = sample[\"offset_mapping\"]\n        sample_id = sample[\"id\"]\n        sample_text = sample[\"text\"]\n        sample_input_ids = sample[\"input_ids\"]\n        sample_pred_scores = sample[\"pred_scores\"]\n        sample_preds = []\n\n        if len(preds) < len(offset_mapping):\n            preds = preds + [\"O\"] * (len(offset_mapping) - len(preds))\n            sample_pred_scores = sample_pred_scores + [0] * (len(offset_mapping) - len(sample_pred_scores))\n\n        idx = 0\n        phrase_preds = []\n        while idx < len(offset_mapping):\n            start, _ = offset_mapping[idx]\n            if preds[idx] != \"O\":\n                label = preds[idx][2:]\n            else:\n                label = \"O\"\n            phrase_scores = []\n            phrase_scores.append(sample_pred_scores[idx])\n            idx += 1\n            while idx < len(offset_mapping):\n                if label == \"O\":\n                    matching_label = \"O\"\n                else:\n                    matching_label = f\"I-{label}\"\n                if preds[idx] == matching_label:\n                    _, end = offset_mapping[idx]\n                    phrase_scores.append(sample_pred_scores[idx])\n                    idx += 1\n                else:\n                    break\n            if \"end\" in locals():\n                phrase = sample_text[start:end]\n                phrase_preds.append((phrase, start, end, label, phrase_scores))\n\n        temp_df = []\n        for phrase_idx, (phrase, start, end, label, phrase_scores) in enumerate(phrase_preds):\n            word_start = len(sample_text[:start].split())\n            word_end = word_start + len(sample_text[start:end].split())\n            word_end = min(word_end, len(sample_text.split()))\n            ps = \" \".join([str(x) for x in range(word_start, word_end)])\n            if label != \"O\":\n                if sum(phrase_scores) / len(phrase_scores) >= proba_thresh[label]:\n                    if len(ps.split()) >= min_thresh[label]:\n                        temp_df.append((sample_id, label, ps))\n\n        temp_df = pd.DataFrame(temp_df, columns=[\"id\", \"class\", \"predictionstring\"])\n        submission.append(temp_df)\n\n    submission = pd.concat(submission).reset_index(drop=True)\n    submission = link_evidence(submission)\n    return submission","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:33:11.276746Z","iopub.execute_input":"2022-03-15T13:33:11.277056Z","iopub.status.idle":"2022-03-15T13:33:11.299893Z","shell.execute_reply.started":"2022-03-15T13:33:11.277019Z","shell.execute_reply":"2022-03-15T13:33:11.299222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/feedback-prize-2021/train.csv\")\n\ndef score_per_fold(fold_submission,fold_ids,train_df=train_df):\n    \n    train_fold_i = train_df[train_df.id.isin(fold_ids)]\n    score = kaggle_score(fold_submission, train_fold_i, return_details=False)\n    return score","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:16:10.233109Z","iopub.execute_input":"2022-03-15T13:16:10.233418Z","iopub.status.idle":"2022-03-15T13:16:11.162611Z","shell.execute_reply.started":"2022-03-15T13:16:10.233383Z","shell.execute_reply":"2022-03-15T13:16:11.1617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def grid_search(dict_preds,min_thresh_list,proba_tresh_list,alpha_list):\n    \n    results=[]\n    \n    for alpha in alpha_list:    \n        dict_preds = weighting_pred(dict_preds,alpha=alpha)\n\n        folds,folds_id = creating_predictions_per_fold(dict_preds)\n        \n        for pt in proba_thresh_list:\n            for mt in min_thresh_list:\n                \n                scores=[]\n                for f in tqdm(folds.values()):\n                    fold_submission = prepare_submission_df_per_fold(test_samples=f,proba_thresh=pt,min_thresh=mt)\n                    scores.append(score_per_fold(fold_submission,folds_ids,train_df=train_df))\n                result=dict(alpha=alpha,proba_thresh=pt,min_thresh=mt,scores=scores)\n                results.append(result)\n        \n    return results","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:50:05.049276Z","iopub.execute_input":"2022-03-15T13:50:05.050086Z","iopub.status.idle":"2022-03-15T13:50:05.057968Z","shell.execute_reply.started":"2022-03-15T13:50:05.050035Z","shell.execute_reply":"2022-03-15T13:50:05.057056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"proba_thresh_list = [{\n    \"Lead\": 0.7,\n    \"Position\": 0.55,\n    \"Evidence\": 0.65,\n    \"Claim\": 0.55,\n    \"Concluding Statement\": 0.7,\n    \"Counterclaim\": 0.5,\n    \"Rebuttal\": 0.55,\n}]\n\nmin_thresh_list = [{\n    \"Lead\": 9,\n    \"Position\": 5,\n    \"Evidence\": 14,\n    \"Claim\": 3,\n    \"Concluding Statement\": 11,\n    \"Counterclaim\": 6,\n    \"Rebuttal\": 4,\n}]\n\nalpha_list = [.5]","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:25:29.051732Z","iopub.execute_input":"2022-03-15T13:25:29.052021Z","iopub.status.idle":"2022-03-15T13:25:29.059176Z","shell.execute_reply.started":"2022-03-15T13:25:29.051988Z","shell.execute_reply":"2022-03-15T13:25:29.058081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading predictions\nwith open(\"../input/preds-cv/dict_all_preds.pickle\", 'rb') as f:\n    dict_preds = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T12:30:48.746522Z","iopub.execute_input":"2022-03-15T12:30:48.747311Z","iopub.status.idle":"2022-03-15T12:30:49.780489Z","shell.execute_reply.started":"2022-03-15T12:30:48.747253Z","shell.execute_reply":"2022-03-15T12:30:49.779421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_preds = weighting_pred(dict_preds,alpha=.5)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T12:36:04.302419Z","iopub.execute_input":"2022-03-15T12:36:04.303196Z","iopub.status.idle":"2022-03-15T12:37:23.462Z","shell.execute_reply.started":"2022-03-15T12:36:04.303149Z","shell.execute_reply":"2022-03-15T12:37:23.460865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds,folds_id = creating_predictions_per_fold(dict_preds)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T12:36:04.302419Z","iopub.execute_input":"2022-03-15T12:36:04.303196Z","iopub.status.idle":"2022-03-15T12:37:23.462Z","shell.execute_reply.started":"2022-03-15T12:36:04.303149Z","shell.execute_reply":"2022-03-15T12:37:23.460865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nres = grid_search(dict_preds,min_thresh_list,proba_thresh_list,alpha_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:50:32.240133Z","iopub.execute_input":"2022-03-15T13:50:32.240435Z","iopub.status.idle":"2022-03-15T13:51:47.172901Z","shell.execute_reply.started":"2022-03-15T13:50:32.240402Z","shell.execute_reply":"2022-03-15T13:51:47.171944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}