{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "seventh-festival",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "exceptional-parliament",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:56:38.781270Z",
     "start_time": "2022-01-06T22:56:38.743400Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.display import HTML\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from evalstudent import metrics\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cross-juice",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:51:00.153190Z",
     "start_time": "2022-01-06T22:51:00.093828Z"
    }
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-tolerance",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-assault",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Display classes on essay texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "saved-enlargement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:51:37.744467Z",
     "start_time": "2022-01-06T22:51:37.691944Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CLASSES_COLORS = {\n",
    "    \"Lead\": \"Grey\",\n",
    "    \"Position\": \"YellowGreen\",\n",
    "    \"Claim\": \"#F1C40F\",\n",
    "    \"Counterclaim\": \"#E67E22\",\n",
    "    \"Rebuttal\": \"#873600\",\n",
    "    \"Evidence\": \"#3498DB\",\n",
    "    \"Concluding Statement\": \"Green\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-england",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The following function print the essay text (keeping its exact original formatting) using colors to highlight discourse elements and their classes.\n",
    "\n",
    "It uses only `predictionstring`, which is useful to display models predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sapphire-orange",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:51:38.063171Z",
     "start_time": "2022-01-06T22:51:38.004834Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None # Disabling some pandas warning\n",
    "\n",
    "def display_classes(essay_id, train_df):\n",
    "    # Handling submission format :\n",
    "    discourse_type = \"class\" if \"discourse_type\" not in train_df.columns else \"discourse_type\"\n",
    "    \n",
    "    elements_df = train_df[train_df[\"id\"] == essay_id]\n",
    "    essay_text = open(f'../raw_data/train/{essay_id}.txt').read()\n",
    "    essay_words = essay_text.split()\n",
    "    formatted_essay = \"\"\n",
    "    \n",
    "    # First we make sure discourse elements are in the text order\n",
    "    elements_df[\"prediction_list\"] = elements_df[\"predictionstring\"].map(lambda x : x.split())\n",
    "    elements_df[\"start_word_index\"] = elements_df[\"prediction_list\"].map(lambda x : int(x[0]))\n",
    "    elements_df.sort_values(\"start_word_index\", inplace=True)\n",
    "\n",
    "    # Then for each discourse element, we go word by word trough the original essay text\n",
    "    # and then we highlight the exact part of the essay corresponding to the discourse class.\n",
    "    end_char = 0\n",
    "    for i, element in elements_df.iterrows():\n",
    "        start_word = essay_words[element[\"start_word_index\"]] \n",
    "        start_char = essay_text[end_char:].find(start_word) + len(essay_text[:end_char])\n",
    "        formatted_essay += essay_text[end_char:start_char]\n",
    "        for word_index in element[\"prediction_list\"]:\n",
    "            word = essay_words[int(word_index)]\n",
    "            word_position = essay_text[end_char:].find(word)\n",
    "            if word_position == -1:\n",
    "                return \"Formatting failed\"\n",
    "            end_char = word_position + len(essay_text[:end_char]) + len(word)\n",
    "        formatted_essay += f\"|<span style='color:{CLASSES_COLORS[element[discourse_type]]}'>{essay_text[start_char:end_char]}</span>\"\n",
    "    formatted_essay = formatted_essay.replace(\"\\n\", \"<br>\")\n",
    "    color_labels = \" \".join([\n",
    "        f\"|<span style='color:{CLASSES_COLORS[class_]}'>{class_}</span>\"\n",
    "        for class_ in CLASSES_COLORS.keys()])\n",
    "    return HTML(color_labels + \"<br><br>\" + formatted_essay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-debut",
   "metadata": {},
   "source": [
    "## Generating predictionstring from discourse_start/end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-dakota",
   "metadata": {},
   "source": [
    "The following snippet of code was copy pasted from [this Kaggle thread](https://www.kaggle.com/c/feedback-prize-2021/discussion/297591) and is the \"official\" way `predictionstring` is computed from `discourse_start/end`. It can be useful for models that output a prediction with character index.\n",
    "```python\n",
    "char_start = discourse_start\n",
    "char_end = discourse_end\n",
    "word_start = len(full_text[:char_start].split())\n",
    "word_end = word_start + len(full_text[char_start:char_end].split())\n",
    "word_end = min( word_end, len(full_text.split()) )\n",
    "predictionstring = \" \".join( [str(x) for x in range(word_start,word_end)] )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-market",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-amendment",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "informational-outdoors",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:10.532937Z",
     "start_time": "2022-01-06T22:52:09.722780Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../../raw_data/train.csv\", dtype = {\"discourse_id\": int, \"discourse_start\": int, \"discourse_end\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hearing-devices",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:11.025697Z",
     "start_time": "2022-01-06T22:52:10.946477Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627660524</td>\n",
       "      <td>8</td>\n",
       "      <td>229</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627653021</td>\n",
       "      <td>230</td>\n",
       "      <td>312</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627671020</td>\n",
       "      <td>313</td>\n",
       "      <td>401</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627696365</td>\n",
       "      <td>402</td>\n",
       "      <td>758</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627759780</td>\n",
       "      <td>759</td>\n",
       "      <td>886</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id   discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1622627660524                8            229   \n",
       "1  423A1CA112E2  1622627653021              230            312   \n",
       "2  423A1CA112E2  1622627671020              313            401   \n",
       "3  423A1CA112E2  1622627696365              402            758   \n",
       "4  423A1CA112E2  1622627759780              759            886   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-vinyl",
   "metadata": {},
   "source": [
    "## Class balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-welsh",
   "metadata": {},
   "source": [
    "We have an important class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "demanding-genetics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:12.098938Z",
     "start_time": "2022-01-06T22:52:12.032795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claim                   0.347959\n",
       "Evidence                0.316731\n",
       "Position                0.106859\n",
       "Concluding Statement    0.093594\n",
       "Lead                    0.064487\n",
       "Counterclaim            0.040314\n",
       "Rebuttal                0.030057\n",
       "Name: discourse_type, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"discourse_type\"].value_counts()/train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-saskatchewan",
   "metadata": {},
   "source": [
    "## Are discourse elements full sentences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-semester",
   "metadata": {},
   "source": [
    "Discourse elements that are sentences or groups of sentences (ie: starts with an uppercase letter and ends with a mark). The real number is higher because some students forget uppercase letters or final marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "professional-revision",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:12.825825Z",
     "start_time": "2022-01-06T22:52:12.724520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5753778769586883"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_elements = [\n",
    "    (text[0].isupper() or text[1].isupper())\n",
    "    and (text[-1] in \".?!\" or text[-2] in \".?!\")\n",
    "    for text in train_df[\"discourse_text\"]\n",
    "]\n",
    "sentences_elements.count(True)/len(sentences_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-explanation",
   "metadata": {},
   "source": [
    "Breakdown by discourse class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "amazing-inside",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:13.295288Z",
     "start_time": "2022-01-06T22:52:13.073249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lead': 0.7219774314884471,\n",
       " 'Position': 0.510798365652766,\n",
       " 'Evidence': 0.7472539494989279,\n",
       " 'Claim': 0.43530911408540474,\n",
       " 'Concluding Statement': 0.5780821917808219,\n",
       " 'Counterclaim': 0.45212308750214886,\n",
       " 'Rebuttal': 0.45768964722158173}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_ratio = {}\n",
    "for class_ in train_df[\"discourse_type\"].unique():\n",
    "    class_df = train_df[\"discourse_text\"][train_df[\"discourse_type\"] == class_]\n",
    "    sentences_elements = [\n",
    "        (text[0].isupper() or text[1].isupper())\n",
    "        and (text[-1] in \".?!\" or text[-2] in \".?!\")\n",
    "        for text in class_df\n",
    "    ]\n",
    "    sentences_ratio.update({class_: sentences_elements.count(True)/len(sentences_elements)})\n",
    "sentences_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-disclosure",
   "metadata": {},
   "source": [
    "## Super Naive Bayesline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-grill",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T09:12:47.655042Z",
     "start_time": "2021-12-29T09:12:47.572057Z"
    }
   },
   "source": [
    "Average count of discourse classes per essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "vital-spectrum",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:13.568375Z",
     "start_time": "2022-01-06T22:52:13.431098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discourse_type\n",
       "Claim                   3.363569\n",
       "Concluding Statement    1.006484\n",
       "Counterclaim            1.271198\n",
       "Evidence                2.939035\n",
       "Lead                    1.000430\n",
       "Position                1.003449\n",
       "Rebuttal                1.205392\n",
       "Name: discourse_id, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_ratio = train_df[[\"id\", \"discourse_id\", \"discourse_type\"]]\\\n",
    "    .groupby([\"id\", \"discourse_type\"]).count()\\\n",
    "    .groupby(\"discourse_type\").mean()\\\n",
    "    .squeeze()\n",
    "classes_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-december",
   "metadata": {},
   "source": [
    "The strategy is to identify the following numbers of discourse classes when we \"predict\" a new essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "civic-examination",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:13.750363Z",
     "start_time": "2022-01-06T22:52:13.681908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discourse_type\n",
       "Claim                   3\n",
       "Concluding Statement    1\n",
       "Counterclaim            1\n",
       "Evidence                3\n",
       "Lead                    1\n",
       "Position                1\n",
       "Rebuttal                1\n",
       "Name: discourse_id, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_ratio_rounded = classes_ratio.round().astype(int)\n",
    "classes_ratio_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adequate-provincial",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:13.867408Z",
     "start_time": "2022-01-06T22:52:13.812647Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train_df[\"discourse_text\"]\n",
    "y = train_df[\"discourse_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "olympic-allen",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:20.687259Z",
     "start_time": "2022-01-06T22:52:13.934817Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=False)\n",
    "X_vec = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-vector",
   "metadata": {},
   "source": [
    "We use `ComplementNB` which is better suited than `MultinomialNB` for imbalanced classes (according to Sklearn doc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "valuable-reputation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:21.417890Z",
     "start_time": "2022-01-06T22:52:20.690155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ComplementNB()\n",
    "model.fit(X_vec, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "choice-helena",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:21.729369Z",
     "start_time": "2022-01-06T22:52:21.423930Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6329620979534697"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_vec, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-wilderness",
   "metadata": {},
   "source": [
    "Prediction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "medieval-assignment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:36.591776Z",
     "start_time": "2022-01-06T22:52:36.549553Z"
    }
   },
   "outputs": [],
   "source": [
    "def bayesline_predict(essay_id):\n",
    "    essay_text = open(f'../../raw_data/train/{essay_id}.txt').read()\n",
    "\n",
    "    # For each sentence, we compute the probability of belonging to each class, and store this into a Dataframe\n",
    "    sentences = sent_tokenize(essay_text)\n",
    "    predictions_matrix = pd.DataFrame(model.predict_proba(vectorizer.transform(sentences)), columns=model.classes_)\n",
    "\n",
    "    # Now, we assign a defined number of sentences to each class using the numbers in `classes_ratio_rounded`.\n",
    "    # To do so, we take the sentence with the highest probability of belonging to a class, assign it to this class,\n",
    "    # and repeat until all classes have the defined number of sentences assigned.\n",
    "    prediction = []\n",
    "    classes_count = classes_ratio_rounded.copy()\n",
    "    sentences_nb = min(classes_count.sum(), len(sentences))\n",
    "    while len(prediction) < sentences_nb :\n",
    "        highest_score_class = predictions_matrix.max().idxmax()\n",
    "        highest_score_element = predictions_matrix[highest_score_class].idxmax()\n",
    "        prediction.append((highest_score_element, highest_score_class))\n",
    "        predictions_matrix.drop(highest_score_element, inplace=True)\n",
    "        classes_count[highest_score_class] -= 1\n",
    "        if classes_count[highest_score_class] == 0:\n",
    "            predictions_matrix.drop(columns=highest_score_class, inplace=True)\n",
    "    prediction\n",
    "\n",
    "    # To generate the submission DataFrame, we need to match sentences number and words index.\n",
    "    sentences_words_index = []\n",
    "    word_index = 0\n",
    "    for sentence in sentences:\n",
    "        sentence_length = len(sentence.split())\n",
    "        sentences_words_index.append(\" \".join([str(i) for i in range(word_index, word_index+sentence_length)]))\n",
    "        word_index += sentence_length\n",
    "    sentences_words_index\n",
    "\n",
    "    # Returning the submission DataFrame\n",
    "    submission = [[essay_id, element[1], sentences_words_index[element[0]]] for element in prediction]\n",
    "    return pd.DataFrame(submission, columns=[\"id\", \"class\", \"predictionstring\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "forbidden-animation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:45.083183Z",
     "start_time": "2022-01-06T22:52:44.857290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " {'Claim': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0},\n",
       "  'Lead': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0},\n",
       "  'Rebuttal': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0},\n",
       "  'Position': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0},\n",
       "  'Concluding Statement': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0},\n",
       "  'Evidence': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0},\n",
       "  'Counterclaim': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.kaggle_score(bayesline_predict(\"423A1CA112E2\"), train_df[train_df[\"id\"] == \"423A1CA112E2\"], return_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abstract-spider",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:54.343945Z",
     "start_time": "2022-01-06T22:52:54.163006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " {'Claim': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0},\n",
       "  'Lead': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0},\n",
       "  'Position': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0},\n",
       "  'Concluding Statement': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0},\n",
       "  'Evidence': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = train_df[train_df[\"id\"] == \"423A1CA112E2\"][[\"id\", \"discourse_type\", \"predictionstring\"]].copy()\n",
    "test[\"class\"] = test[\"discourse_type\"]\n",
    "metrics.kaggle_score(test, train_df[train_df[\"id\"] == \"423A1CA112E2\"], return_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-hamburg",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:21.840776Z",
     "start_time": "2022-01-06T22:52:14.895Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_classes(\"423A1CA112E2\", bayesline_predict(\"423A1CA112E2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-there",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:21.843777Z",
     "start_time": "2022-01-06T22:52:15.016Z"
    }
   },
   "outputs": [],
   "source": [
    "display_classes(\"423A1CA112E2\", train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-channels",
   "metadata": {},
   "source": [
    "# Unused utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-fitting",
   "metadata": {},
   "source": [
    "`display_classes_2` uses the `discourse_text` field of `train_df`. It is generally better than `display_classes_3` (which uses `discourse_start/end`), but when a element is present several times in the essay text, things get messy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-nylon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:21.846305Z",
     "start_time": "2022-01-06T22:52:15.831Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_classes_2(essay_id, train_df):\n",
    "    elements_df = train_df[train_df[\"id\"] == essay_id]\n",
    "    essay_text = open(f'../raw_data/train/{essay_id}.txt').read()\n",
    "    for i, element in elements_df.iterrows():\n",
    "        element_text = element[\"discourse_text\"].strip()\n",
    "        # The stripping above is needed to make sure the replace below works\n",
    "        if not element_text in essay_text:\n",
    "            return \"Formatting failed\"\n",
    "        essay_text = essay_text.replace(\n",
    "            element_text,\n",
    "            f\"|<span style='color:{CLASSES_COLORS[element['discourse_type']]}'>{element_text}</span>\"\n",
    "        )\n",
    "    essay_text = essay_text.replace(\"\\n\", \"<br>\")\n",
    "    color_labels = \" - \".join([\n",
    "        f\"<span style='color:{CLASSES_COLORS[class_]}'>{class_}</span>\"\n",
    "        for class_ in CLASSES_COLORS.keys()])\n",
    "    return HTML(color_labels + \"<br><br>\" + essay_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-condition",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:21.848705Z",
     "start_time": "2022-01-06T22:52:15.959Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_discourse(text, type_):\n",
    "    if text:\n",
    "        text = text.replace(\"\\n\", \"<br>\")\n",
    "        return f\"|<span style='color:{CLASSES_COLORS.get(type_)}'>{text}</span>\"\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-singer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:52:21.852071Z",
     "start_time": "2022-01-06T22:52:16.088Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_classes_3(essay_id, train_df):\n",
    "    elements_df = train_df[train_df[\"id\"] == essay_id]\n",
    "    essay_text = open(f'../raw_data/train/{essay_id}.txt').read()\n",
    "    formatted_elements = \"\"\n",
    "    char_pointer = 0\n",
    "    for i, element in elements_df.iterrows():\n",
    "        unlabelled_element = essay_text[char_pointer:element['discourse_start']]\n",
    "        char_pointer = element['discourse_end'] + 1\n",
    "        discourse_element = essay_text[element['discourse_start']:char_pointer]\n",
    "        formatted_elements +=\\\n",
    "            format_discourse(unlabelled_element, \"Unlabelled\") +\\\n",
    "            format_discourse(discourse_element, element['discourse_type'])\n",
    "    formatted_elements += essay_text[char_pointer:]\n",
    "    color_labels = \" \".join([format_discourse(class_, class_) for class_ in CLASSES_COLORS.keys()])\n",
    "    return HTML(color_labels + \"<br><br>\" + formatted_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-richmond",
   "metadata": {},
   "source": [
    "We maybe can simplify the code using the displaCy tool (https://explosion.ai/demos/displacy-ent), see this example:\n",
    "```python\n",
    "j = 40\n",
    "ents = []\n",
    "for i, row in df[df['id'] == df_f[j][35:-4]].iterrows():\n",
    "    ents.append({\n",
    "                    'start': int(row['discourse_start']), \n",
    "                     'end': int(row['discourse_end']), \n",
    "                     'label': row['discourse_type']\n",
    "                })\n",
    "with open(df_f[j], 'r') as file: data = file.read()\n",
    "\n",
    "doc2 = {\n",
    "    \"text\": data,\n",
    "    \"ents\": ents,\n",
    "}\n",
    "cols = {'Lead': '#dad1f6','Position': '#f9d5de','Claim': '#adcfad','Evidence': '#fbbf9a','Counterclaim': '#bdf2fa','Concluding Statement': '#eea69e','Rebuttal': '#d1f8f4'}\n",
    "options = {\"ents\": df.discourse_type.unique().tolist(), \"colors\": cols}\n",
    "displacy.render(doc2, style=\"ent\", options=options, manual=True, jupyter=True);\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
