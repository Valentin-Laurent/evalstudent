{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "seventh-festival",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exceptional-parliament",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:23.975055Z",
     "start_time": "2022-01-05T23:20:22.968817Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.display import HTML\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from nltk.tokenize import sent_tokenize\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-tolerance",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-assault",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Display classes on essay texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "saved-enlargement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:25.585357Z",
     "start_time": "2022-01-05T23:20:25.580510Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CLASSES_COLORS = {\n",
    "    \"Lead\": \"Grey\",\n",
    "    \"Position\": \"YellowGreen\",\n",
    "    \"Claim\": \"#F1C40F\",\n",
    "    \"Counterclaim\": \"#E67E22\",\n",
    "    \"Rebuttal\": \"#873600\",\n",
    "    \"Evidence\": \"#3498DB\",\n",
    "    \"Concluding Statement\": \"Green\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-england",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The following function print the essay text (keeping its exact original formatting) using colors to highlight discourse elements and their classes.\n",
    "\n",
    "It uses only `predictionstring`, which is useful to display models predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sapphire-orange",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:26.146830Z",
     "start_time": "2022-01-05T23:20:26.135828Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None # Disabling some pandas warning\n",
    "\n",
    "def display_classes(essay_id, train_df):\n",
    "    # Handling submission format :\n",
    "    discourse_type = \"class\" if \"discourse_type\" not in train_df.columns else \"discourse_type\"\n",
    "    \n",
    "    elements_df = train_df[train_df[\"id\"] == essay_id]\n",
    "    essay_text = open(f'../raw_data/train/{essay_id}.txt').read()\n",
    "    essay_words = essay_text.split()\n",
    "    formatted_essay = \"\"\n",
    "    \n",
    "    # First we make sure discourse elements are in the text order\n",
    "    elements_df[\"prediction_list\"] = elements_df[\"predictionstring\"].map(lambda x : x.split())\n",
    "    elements_df[\"start_word_index\"] = elements_df[\"prediction_list\"].map(lambda x : int(x[0]))\n",
    "    elements_df.sort_values(\"start_word_index\", inplace=True)\n",
    "\n",
    "    # Then for each discourse element, we go word by word trough the original essay text\n",
    "    # and then we highlight the exact part of the essay corresponding to the discourse class.\n",
    "    end_char = 0\n",
    "    for i, element in elements_df.iterrows():\n",
    "        start_word = essay_words[element[\"start_word_index\"]] \n",
    "        start_char = essay_text[end_char:].find(start_word) + len(essay_text[:end_char])\n",
    "        formatted_essay += essay_text[end_char:start_char]\n",
    "        for word_index in element[\"prediction_list\"]:\n",
    "            word = essay_words[int(word_index)]\n",
    "            word_position = essay_text[end_char:].find(word)\n",
    "            if word_position == -1:\n",
    "                return \"Formatting failed\"\n",
    "            end_char = word_position + len(essay_text[:end_char]) + len(word)\n",
    "        formatted_essay += f\"|<span style='color:{CLASSES_COLORS[element[discourse_type]]}'>{essay_text[start_char:end_char]}</span>\"\n",
    "    formatted_essay = formatted_essay.replace(\"\\n\", \"<br>\")\n",
    "    color_labels = \" \".join([\n",
    "        f\"|<span style='color:{CLASSES_COLORS[class_]}'>{class_}</span>\"\n",
    "        for class_ in CLASSES_COLORS.keys()])\n",
    "    return HTML(color_labels + \"<br><br>\" + formatted_essay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-qatar",
   "metadata": {},
   "source": [
    "## Evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-publicity",
   "metadata": {},
   "source": [
    "Code adapted from Rob Mulla (@robikscube) (https://www.kaggle.com/robikscube/student-writing-competition-twitch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-conclusion",
   "metadata": {},
   "source": [
    "Can most probably be optimized (if we have performance issues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "wooden-adult",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:57:09.010561Z",
     "start_time": "2022-01-05T23:57:08.968009Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_overlap(row):\n",
    "    \"\"\"\n",
    "    Calculates the overlap between prediction and\n",
    "    ground truth and overlap percentages used for determining\n",
    "    true positives.\n",
    "    \"\"\"\n",
    "    set_pred = set(row.predictionstring_pred.split(\" \"))\n",
    "    set_gt = set(row.predictionstring_gt.split(\" \"))\n",
    "    # Length of each and intersection\n",
    "    len_gt = len(set_gt)\n",
    "    len_pred = len(set_pred)\n",
    "    inter = len(set_gt.intersection(set_pred))\n",
    "    overlap_1 = inter / len_gt\n",
    "    overlap_2 = inter / len_pred\n",
    "    return [overlap_1, overlap_2]\n",
    "\n",
    "\n",
    "def get_scores(pred_df, gt_df):\n",
    "    \"\"\"\n",
    "    Returns precision, recall and f1 scores.\n",
    "    \"\"\"\n",
    "    gt_df = (\n",
    "        gt_df[[\"id\", \"discourse_type\", \"predictionstring\"]]\n",
    "        .reset_index(drop=True)\n",
    "        .copy()\n",
    "    )\n",
    "    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]].reset_index(drop=True).copy()\n",
    "    pred_df[\"pred_id\"] = pred_df.index\n",
    "    gt_df[\"gt_id\"] = gt_df.index\n",
    "    # Step 1. all ground truths and predictions for a given class are compared.\n",
    "    joined = pred_df.merge(\n",
    "        gt_df,\n",
    "        left_on=[\"id\", \"class\"],\n",
    "        right_on=[\"id\", \"discourse_type\"],\n",
    "        how=\"outer\",\n",
    "        suffixes=(\"_pred\", \"_gt\"),\n",
    "    )\n",
    "    joined[\"predictionstring_gt\"] = joined[\"predictionstring_gt\"].fillna(\" \")\n",
    "    joined[\"predictionstring_pred\"] = joined[\"predictionstring_pred\"].fillna(\" \")\n",
    "\n",
    "    joined[\"overlaps\"] = joined.apply(calc_overlap, axis=1)\n",
    "\n",
    "    # 2. If the overlap between the ground truth and prediction is >= 0.5,\n",
    "    # and the overlap between the prediction and the ground truth >= 0.5,\n",
    "    # the prediction is a match and considered a true positive.\n",
    "    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "    \n",
    "    # The 2 following lines can be avoided if calc_overlap returns directly the proper data type\n",
    "    joined[\"overlap1\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[0])\n",
    "    joined[\"overlap2\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[1])\n",
    "\n",
    "    joined[\"potential_TP\"] = (joined[\"overlap1\"] >= 0.5) & (joined[\"overlap2\"] >= 0.5)\n",
    "    joined[\"max_overlap\"] = joined[[\"overlap1\", \"overlap2\"]].max(axis=1)\n",
    "    tp_pred_ids = (\n",
    "        joined.query(\"potential_TP\")\n",
    "        .sort_values(\"max_overlap\", ascending=False)\n",
    "        .groupby([\"id\", \"predictionstring_gt\"])\n",
    "        .first()[\"pred_id\"]\n",
    "        .values\n",
    "    )\n",
    "\n",
    "    # 3. Any unmatched ground truths are false negatives\n",
    "    # and any unmatched predictions are false positives.\n",
    "    fp_pred_ids = [p for p in joined[\"pred_id\"].unique() if p not in tp_pred_ids]\n",
    "\n",
    "    matched_gt_ids = joined.query(\"potential_TP\")[\"gt_id\"].unique()\n",
    "    unmatched_gt_ids = [c for c in joined[\"gt_id\"].unique() if c not in matched_gt_ids]\n",
    "\n",
    "    # Get numbers of each type\n",
    "    TP = len(tp_pred_ids)\n",
    "    FP = len(fp_pred_ids)\n",
    "    FN = len(unmatched_gt_ids)\n",
    "    \n",
    "    # return metrics\n",
    "    return {\n",
    "        \"precision\" : TP / (TP + FP),\n",
    "        \"recall\" : TP / (TP + FN),\n",
    "        \"f1\" : TP / (TP + 0.5 * (FP + FN))\n",
    "    }\n",
    "\n",
    "\n",
    "def kaggle_score(pred_df, gt_df, return_details=False):\n",
    "    \"\"\"\n",
    "    A function that scores for the kaggle Student Writing Competition\n",
    "\n",
    "    Uses the steps in the evaluation page here:\n",
    "        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
    "    \"\"\"\n",
    "    detailed_scores = {}\n",
    "    # We have to get the existing classes dynamically otherwise the code will break :\n",
    "    classes = set(pred_df[\"class\"].unique()) | set(gt_df[\"discourse_type\"].unique())\n",
    "    for class_ in classes:\n",
    "        pred_subset = pred_df.loc[pred_df[\"class\"] == class_].reset_index(drop=True).copy()\n",
    "        gt_subset = gt_df.loc[gt_df[\"discourse_type\"] == class_].reset_index(drop=True).copy()\n",
    "        class_scores = get_scores(pred_subset, gt_subset)\n",
    "        detailed_scores[class_] = class_scores\n",
    "    f1_score = np.mean([class_scores[\"f1\"] for class_scores in detailed_scores.values()])\n",
    "    if return_details:\n",
    "        return f1_score, detailed_scores\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-debut",
   "metadata": {},
   "source": [
    "## Generating predictionstring from discourse_start/end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-dakota",
   "metadata": {},
   "source": [
    "The following snippet of code was copy pasted from [this Kaggle thread](https://www.kaggle.com/c/feedback-prize-2021/discussion/297591) and is the \"official\" way `predictionstring` is computed from `discourse_start/end`. It can be useful for models that output a prediction with character index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-friendship",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:27.682250Z",
     "start_time": "2022-01-05T23:20:27.680Z"
    }
   },
   "outputs": [],
   "source": [
    "char_start = discourse_start\n",
    "char_end = discourse_end\n",
    "word_start = len(full_text[:char_start].split())\n",
    "word_end = word_start + len(full_text[char_start:char_end].split())\n",
    "word_end = min( word_end, len(full_text.split()) )\n",
    "predictionstring = \" \".join( [str(x) for x in range(word_start,word_end)] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-market",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-amendment",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "informational-outdoors",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:29.394352Z",
     "start_time": "2022-01-05T23:20:28.114245Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../raw_data/train.csv\", dtype = {\"discourse_id\": int, \"discourse_start\": int, \"discourse_end\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hearing-devices",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:29.452015Z",
     "start_time": "2022-01-05T23:20:29.396935Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627660524</td>\n",
       "      <td>8</td>\n",
       "      <td>229</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627653021</td>\n",
       "      <td>230</td>\n",
       "      <td>312</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627671020</td>\n",
       "      <td>313</td>\n",
       "      <td>401</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627696365</td>\n",
       "      <td>402</td>\n",
       "      <td>758</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627759780</td>\n",
       "      <td>759</td>\n",
       "      <td>886</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id   discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1622627660524                8            229   \n",
       "1  423A1CA112E2  1622627653021              230            312   \n",
       "2  423A1CA112E2  1622627671020              313            401   \n",
       "3  423A1CA112E2  1622627696365              402            758   \n",
       "4  423A1CA112E2  1622627759780              759            886   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-vinyl",
   "metadata": {},
   "source": [
    "## Class balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-welsh",
   "metadata": {},
   "source": [
    "We have an important class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "demanding-genetics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:29.504512Z",
     "start_time": "2022-01-05T23:20:29.458438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claim                   0.347959\n",
       "Evidence                0.316731\n",
       "Position                0.106859\n",
       "Concluding Statement    0.093594\n",
       "Lead                    0.064487\n",
       "Counterclaim            0.040314\n",
       "Rebuttal                0.030057\n",
       "Name: discourse_type, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"discourse_type\"].value_counts()/train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-saskatchewan",
   "metadata": {},
   "source": [
    "## Are discourse elements full sentences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-semester",
   "metadata": {},
   "source": [
    "Discourse elements that are sentences or groups of sentences (ie: starts with an uppercase letter and ends with a mark). The real number is higher because some students forget uppercase letters or final marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "professional-revision",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:29.608701Z",
     "start_time": "2022-01-05T23:20:29.507506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5753778769586883"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_elements = [\n",
    "    (text[0].isupper() or text[1].isupper())\n",
    "    and (text[-1] in \".?!\" or text[-2] in \".?!\")\n",
    "    for text in train_df[\"discourse_text\"]\n",
    "]\n",
    "sentences_elements.count(True)/len(sentences_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-explanation",
   "metadata": {},
   "source": [
    "Breakdown by discourse class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "amazing-inside",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:29.837992Z",
     "start_time": "2022-01-05T23:20:29.616232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lead': 0.7219774314884471,\n",
       " 'Position': 0.510798365652766,\n",
       " 'Evidence': 0.7472539494989279,\n",
       " 'Claim': 0.43530911408540474,\n",
       " 'Concluding Statement': 0.5780821917808219,\n",
       " 'Counterclaim': 0.45212308750214886,\n",
       " 'Rebuttal': 0.45768964722158173}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_ratio = {}\n",
    "for class_ in train_df[\"discourse_type\"].unique():\n",
    "    class_df = train_df[\"discourse_text\"][train_df[\"discourse_type\"] == class_]\n",
    "    sentences_elements = [\n",
    "        (text[0].isupper() or text[1].isupper())\n",
    "        and (text[-1] in \".?!\" or text[-2] in \".?!\")\n",
    "        for text in class_df\n",
    "    ]\n",
    "    sentences_ratio.update({class_: sentences_elements.count(True)/len(sentences_elements)})\n",
    "sentences_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-disclosure",
   "metadata": {},
   "source": [
    "## Super Naive Bayesline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-grill",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T09:12:47.655042Z",
     "start_time": "2021-12-29T09:12:47.572057Z"
    }
   },
   "source": [
    "Average count of discourse classes per essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vital-spectrum",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:29.988807Z",
     "start_time": "2022-01-05T23:20:29.842900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discourse_type\n",
       "Claim                   3.363569\n",
       "Concluding Statement    1.006484\n",
       "Counterclaim            1.271198\n",
       "Evidence                2.939035\n",
       "Lead                    1.000430\n",
       "Position                1.003449\n",
       "Rebuttal                1.205392\n",
       "Name: discourse_id, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_ratio = train_df[[\"id\", \"discourse_id\", \"discourse_type\"]]\\\n",
    "    .groupby([\"id\", \"discourse_type\"]).count()\\\n",
    "    .groupby(\"discourse_type\").mean()\\\n",
    "    .squeeze()\n",
    "classes_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-december",
   "metadata": {},
   "source": [
    "The strategy is to identify the following numbers of discourse classes when we \"predict\" a new essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "civic-examination",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:30.025069Z",
     "start_time": "2022-01-05T23:20:29.992851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discourse_type\n",
       "Claim                   3\n",
       "Concluding Statement    1\n",
       "Counterclaim            1\n",
       "Evidence                3\n",
       "Lead                    1\n",
       "Position                1\n",
       "Rebuttal                1\n",
       "Name: discourse_id, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_ratio_rounded = classes_ratio.round().astype(int)\n",
    "classes_ratio_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adequate-provincial",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:30.050447Z",
     "start_time": "2022-01-05T23:20:30.027797Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train_df[\"discourse_text\"]\n",
    "y = train_df[\"discourse_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "olympic-allen",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:36.818442Z",
     "start_time": "2022-01-05T23:20:30.095535Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=False)\n",
    "X_vec = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-vector",
   "metadata": {},
   "source": [
    "We use `ComplementNB` which is better suited than `MultinomialNB` for imbalanced classes (according to Sklearn doc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "valuable-reputation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:37.559278Z",
     "start_time": "2022-01-05T23:20:36.820921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ComplementNB()\n",
    "model.fit(X_vec, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "choice-helena",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:37.830363Z",
     "start_time": "2022-01-05T23:20:37.567153Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6329620979534697"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_vec, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-wilderness",
   "metadata": {},
   "source": [
    "Prediction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "medieval-assignment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:37.844389Z",
     "start_time": "2022-01-05T23:20:37.836815Z"
    }
   },
   "outputs": [],
   "source": [
    "def bayesline_predict(essay_id):\n",
    "    essay_text = open(f'../raw_data/train/{essay_id}.txt').read()\n",
    "\n",
    "    # For each sentence, we compute the probability of belonging to each class, and store this into a Dataframe\n",
    "    sentences = sent_tokenize(essay_text)\n",
    "    predictions_matrix = pd.DataFrame(model.predict_proba(vectorizer.transform(sentences)), columns=model.classes_)\n",
    "\n",
    "    # Now, we assign a defined number of sentences to each class using the numbers in `classes_ratio_rounded`.\n",
    "    # To do so, we take the sentence with the highest probability of belonging to a class, assign it to this class,\n",
    "    # and repeat until all classes have the defined number of sentences assigned.\n",
    "    prediction = []\n",
    "    classes_count = classes_ratio_rounded.copy()\n",
    "    sentences_nb = min(classes_count.sum(), len(sentences))\n",
    "    while len(prediction) < sentences_nb :\n",
    "        highest_score_class = predictions_matrix.max().idxmax()\n",
    "        highest_score_element = predictions_matrix[highest_score_class].idxmax()\n",
    "        prediction.append((highest_score_element, highest_score_class))\n",
    "        predictions_matrix.drop(highest_score_element, inplace=True)\n",
    "        classes_count[highest_score_class] -= 1\n",
    "        if classes_count[highest_score_class] == 0:\n",
    "            predictions_matrix.drop(columns=highest_score_class, inplace=True)\n",
    "    prediction\n",
    "\n",
    "    # To generate the submission DataFrame, we need to match sentences number and words index.\n",
    "    sentences_words_index = []\n",
    "    word_index = 0\n",
    "    for sentence in sentences:\n",
    "        sentence_length = len(sentence.split())\n",
    "        sentences_words_index.append(\" \".join([str(i) for i in range(word_index, word_index+sentence_length)]))\n",
    "        word_index += sentence_length\n",
    "    sentences_words_index\n",
    "\n",
    "    # Returning the submission DataFrame\n",
    "    submission = [[essay_id, element[1], sentences_words_index[element[0]]] for element in prediction]\n",
    "    return pd.DataFrame(submission, columns=[\"id\", \"class\", \"predictionstring\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "forbidden-animation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:57:13.405462Z",
     "start_time": "2022-01-05T23:57:13.134750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " {'Position': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0},\n",
       "  'Rebuttal': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0},\n",
       "  'Evidence': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0},\n",
       "  'Concluding Statement': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0},\n",
       "  'Claim': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0},\n",
       "  'Counterclaim': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0},\n",
       "  'Lead': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_score(bayesline_predict(\"423A1CA112E2\"), train_df[train_df[\"id\"] == \"423A1CA112E2\"], return_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "abstract-spider",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:57:34.054031Z",
     "start_time": "2022-01-05T23:57:33.899482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " {'Lead': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0},\n",
       "  'Position': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0},\n",
       "  'Evidence': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0},\n",
       "  'Concluding Statement': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0},\n",
       "  'Claim': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = train_df[train_df[\"id\"] == \"423A1CA112E2\"][[\"id\", \"discourse_type\", \"predictionstring\"]].copy()\n",
    "test[\"class\"] = test[\"discourse_type\"]\n",
    "kaggle_score(test, train_df[train_df[\"id\"] == \"423A1CA112E2\"], return_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "strange-hamburg",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:57:39.913098Z",
     "start_time": "2022-01-05T23:57:39.871145Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "|<span style='color:Grey'>Lead</span> |<span style='color:YellowGreen'>Position</span> |<span style='color:#F1C40F'>Claim</span> |<span style='color:#E67E22'>Counterclaim</span> |<span style='color:#873600'>Rebuttal</span> |<span style='color:#3498DB'>Evidence</span> |<span style='color:Green'>Concluding Statement</span><br><br>|<span style='color:Grey'>Phones<br><br>Modern humans today are always on their phone.</span> They are always on their phone more than 5 hours a day no stop .All they do is text back and forward and just have group Chats on social media. They even do it while driving. They are some really bad consequences when stuff happens when it comes to a phone. Some certain areas in the United States ban phones from class rooms just because of it.<br><br>|<span style='color:#3498DB'>When people have phones, they know about certain apps that they have .Apps like Facebook Twitter Instagram and Snapchat.</span> |<span style='color:#3498DB'>So like if a friend moves away and you want to be in contact you can still be in contact by posting videos or text messages.</span> |<span style='color:#F1C40F'>People always have different ways how to communicate with a phone.</span> |<span style='color:YellowGreen'>Phones have changed due to our generation.</span><br><br>Driving is one of the way how to get around. People always be on their phones while doing it. |<span style='color:#F1C40F'>Which can cause serious Problems.</span> |<span style='color:Green'>That's why there's a thing that's called no texting while driving. That's a really important thing to remember.</span> |<span style='color:#E67E22'>Some people still do it because they think It's stupid.</span> |<span style='color:#873600'>No matter what they do they still have to obey it because that's the only way how did he save.</span><br><br>|<span style='color:#3498DB'>Sometimes on the news there is either an accident or a suicide.</span> It might involve someone not looking where they're going or tweet that someone sent. It either injury or death. If a mysterious number says I'm going to kill you and they know where you live but you don't know the person's contact<br><br>,It makes you puzzled and make you start to freak out. Which can end up really badly.<br><br>Phones are fine to use and it's also the best way to come over help. If you go through a problem and you can't find help you ,always have a phone there with you. Even though phones are used almost every day as long as you're safe it would come into use if you get into trouble. Make sure you do not be like this phone while you're in the middle of driving. |<span style='color:#F1C40F'>The news always updated when people do something stupid around that involves their phones. The safest way is the best way to stay safe.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_classes(\"423A1CA112E2\", bayesline_predict(\"423A1CA112E2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "incomplete-there",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:57:42.372307Z",
     "start_time": "2022-01-05T23:57:42.334851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "|<span style='color:Grey'>Lead</span> |<span style='color:YellowGreen'>Position</span> |<span style='color:#F1C40F'>Claim</span> |<span style='color:#E67E22'>Counterclaim</span> |<span style='color:#873600'>Rebuttal</span> |<span style='color:#3498DB'>Evidence</span> |<span style='color:Green'>Concluding Statement</span><br><br>Phones<br><br>|<span style='color:Grey'>Modern humans today are always on their phone. They are always on their phone more than 5 hours a day no stop .All they do is text back and forward and just have group Chats on social media. They even do it while driving.</span> |<span style='color:YellowGreen'>They are some really bad consequences when stuff happens when it comes to a phone.</span> |<span style='color:#3498DB'>Some certain areas in the United States ban phones from class rooms just because of it.</span><br><br>|<span style='color:#3498DB'>When people have phones, they know about certain apps that they have .Apps like Facebook Twitter Instagram and Snapchat. So like if a friend moves away and you want to be in contact you can still be in contact by posting videos or text messages. People always have different ways how to communicate with a phone. Phones have changed due to our generation.</span><br><br>|<span style='color:#F1C40F'>Driving is one of the way how to get around. People always be on their phones while doing it. Which can cause serious Problems.</span> |<span style='color:#3498DB'>That's why there's a thing that's called no texting while driving. That's a really important thing to remember. Some people still do it because they think It's stupid. No matter what they do they still have to obey it because that's the only way how did he save.</span><br><br>|<span style='color:#3498DB'>Sometimes on the news there is either an accident or a suicide. It might involve someone not looking where they're going or tweet that someone sent. It either injury or death. If a mysterious number says I'm going to kill you and they know where you live but you don't know the person's contact<br><br>,It makes you puzzled and make you start to freak out. Which can end up really badly.</span><br><br>|<span style='color:#F1C40F'>Phones are fine to use and it's also the best way to come over help.</span> |<span style='color:#3498DB'>If you go through a problem and you can't find help you ,always have a phone there with you. Even though phones are used almost every day as long as you're safe it would come into use if you get into trouble. Make sure you do not be like this phone while you're in the middle of driving.</span> |<span style='color:Green'>The news always updated when people do something stupid around that involves their phones. The safest way is the best way to stay safe.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_classes(\"423A1CA112E2\", train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-channels",
   "metadata": {},
   "source": [
    "# Unused utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-fitting",
   "metadata": {},
   "source": [
    "`display_classes_2` uses the `discourse_text` field of `train_df`. It is generally better than `display_classes_3` (which uses `discourse_start/end`), but when a element is present several times in the essay text, things get messy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-nylon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:38.295233Z",
     "start_time": "2022-01-05T23:20:31.775Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_classes_2(essay_id, train_df):\n",
    "    elements_df = train_df[train_df[\"id\"] == essay_id]\n",
    "    essay_text = open(f'../raw_data/train/{essay_id}.txt').read()\n",
    "    for i, element in elements_df.iterrows():\n",
    "        element_text = element[\"discourse_text\"].strip()\n",
    "        # The stripping above is needed to make sure the replace below works\n",
    "        if not element_text in essay_text:\n",
    "            return \"Formatting failed\"\n",
    "        essay_text = essay_text.replace(\n",
    "            element_text,\n",
    "            f\"|<span style='color:{CLASSES_COLORS[element['discourse_type']]}'>{element_text}</span>\"\n",
    "        )\n",
    "    essay_text = essay_text.replace(\"\\n\", \"<br>\")\n",
    "    color_labels = \" - \".join([\n",
    "        f\"<span style='color:{CLASSES_COLORS[class_]}'>{class_}</span>\"\n",
    "        for class_ in CLASSES_COLORS.keys()])\n",
    "    return HTML(color_labels + \"<br><br>\" + essay_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-condition",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:38.298855Z",
     "start_time": "2022-01-05T23:20:31.907Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_discourse(text, type_):\n",
    "    if text:\n",
    "        text = text.replace(\"\\n\", \"<br>\")\n",
    "        return f\"|<span style='color:{CLASSES_COLORS.get(type_)}'>{text}</span>\"\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-singer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T23:20:38.301920Z",
     "start_time": "2022-01-05T23:20:32.036Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_classes_3(essay_id, train_df):\n",
    "    elements_df = train_df[train_df[\"id\"] == essay_id]\n",
    "    essay_text = open(f'../raw_data/train/{essay_id}.txt').read()\n",
    "    formatted_elements = \"\"\n",
    "    char_pointer = 0\n",
    "    for i, element in elements_df.iterrows():\n",
    "        unlabelled_element = essay_text[char_pointer:element['discourse_start']]\n",
    "        char_pointer = element['discourse_end'] + 1\n",
    "        discourse_element = essay_text[element['discourse_start']:char_pointer]\n",
    "        formatted_elements +=\\\n",
    "            format_discourse(unlabelled_element, \"Unlabelled\") +\\\n",
    "            format_discourse(discourse_element, element['discourse_type'])\n",
    "    formatted_elements += essay_text[char_pointer:]\n",
    "    color_labels = \" \".join([format_discourse(class_, class_) for class_ in CLASSES_COLORS.keys()])\n",
    "    return HTML(color_labels + \"<br><br>\" + formatted_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-richmond",
   "metadata": {},
   "source": [
    "We maybe can simplify the code using the displaCy tool (https://explosion.ai/demos/displacy-ent), see this example:\n",
    "```python\n",
    "j = 40\n",
    "ents = []\n",
    "for i, row in df[df['id'] == df_f[j][35:-4]].iterrows():\n",
    "    ents.append({\n",
    "                    'start': int(row['discourse_start']), \n",
    "                     'end': int(row['discourse_end']), \n",
    "                     'label': row['discourse_type']\n",
    "                })\n",
    "with open(df_f[j], 'r') as file: data = file.read()\n",
    "\n",
    "doc2 = {\n",
    "    \"text\": data,\n",
    "    \"ents\": ents,\n",
    "}\n",
    "cols = {'Lead': '#dad1f6','Position': '#f9d5de','Claim': '#adcfad','Evidence': '#fbbf9a','Counterclaim': '#bdf2fa','Concluding Statement': '#eea69e','Rebuttal': '#d1f8f4'}\n",
    "options = {\"ents\": df.discourse_type.unique().tolist(), \"colors\": cols}\n",
    "displacy.render(doc2, style=\"ent\", options=options, manual=True, jupyter=True);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-tribune",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
